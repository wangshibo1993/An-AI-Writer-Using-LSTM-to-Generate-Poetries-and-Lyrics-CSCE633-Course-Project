{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Embedding, LSTM, Dense, Input, Dropout, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "a = tf.test.is_built_with_cuda()\n",
    "b = tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")     \n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "# set_session(tf.Session(config=config))\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "# SEQ_LENGTH = 3     \n",
    "MAX_NB_WORDS = 10000    \n",
    "# EMBEDDING_DIM = 512     \n",
    "# EMBEDDING_DIM_2 = 512     \n",
    "# EMBEDDING_DIM_3 = 256\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutWords(file_name):\n",
    "    with open(file_name, 'r', encoding='utf8') as f:\n",
    "        content = f.read().replace('\\n', '。')   # 使用句号作为句子的结束符\n",
    "        f.close()\n",
    "    return list(content)\n",
    "\n",
    "def mapWords(cut_word_list):\n",
    "    \"\"\"\n",
    "     set word2index and index2word to build dictionary\n",
    "    :param cut_word_list: Character-level token\n",
    "    :return:word2index和index2word， key <=> value\n",
    "    \"\"\"\n",
    "    vocabulary = sorted(list(set(cut_word_list)))\n",
    "    word_to_index = dict((w, i+2) for i, w in enumerate(vocabulary))\n",
    "    word_to_index[\"PAD\"] = 0   # 填补\n",
    "    word_to_index[\"UNK\"] = 1   # unknown\n",
    "    index_to_word = dict((index, word) for word, index in word_to_index.items())\n",
    "\n",
    "    word_to_index_json = json.dumps(word_to_index)\n",
    "    index_to_word_json = json.dumps(index_to_word)\n",
    "    with open('./word_to_index_word.txt', 'w', encoding='utf8') as w:\n",
    "        w.write(word_to_index_json)\n",
    "        w.close()\n",
    "    with open('./index_to_word_word.txt', 'w', encoding='utf8') as w:\n",
    "        w.write(index_to_word_json)\n",
    "        w.close()\n",
    "    # print(\"len of word_to_index::\", len(word_to_index))\n",
    "    # print(\"len of index_to_word::\", len(index_to_word))\n",
    "    return word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainData(cut_word_list, word_to_index, SEQ_LENGTH):\n",
    "    \"\"\"\n",
    "    :return:X_train, X_val, y_train, y_val：training and validation\n",
    "    \"\"\"\n",
    "    # 生成训练数据\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    data_index = []\n",
    "    n_all_words = len(cut_word_list)\n",
    "    for i in range(0, n_all_words - SEQ_LENGTH - 1):\n",
    "        seq_x_y = cut_word_list[i: i+SEQ_LENGTH + 1]   # SEQ_LENGTH Chinese characters correspond to the next (SEQ_LENGTH+1)th Chinese characters\n",
    "        index_x_y = [word_to_index[elem] for elem in seq_x_y]    \n",
    "        data_index.append(index_x_y)\n",
    "#     np.random.shuffle(data_index)\n",
    "    for i in range(0, len(data_index)):\n",
    "        X_data.append(data_index[i][:SEQ_LENGTH])\n",
    "        y_data.append(data_index[i][SEQ_LENGTH])\n",
    "\n",
    "    #list => tensor\n",
    "    del data_index\n",
    "    gc.collect()\n",
    "    X = np.reshape(X_data, (len(X_data), SEQ_LENGTH))\n",
    "    del X_data\n",
    "    gc.collect()\n",
    "    \n",
    "    y = np_utils.to_categorical(y_data)\n",
    "    del y_data\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1, shuffle=False)\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./train_data/all_5.txt\"\n",
    "cut_word_list = cutWords(file_name)\n",
    "word_to_index, index_to_word = mapWords(cut_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm(ga_individual_solution):\n",
    "    \"\"\"\n",
    "    Using Tensorboard as call_back \n",
    "    \"\"\"\n",
    "#     file_name = \"./train_data/all_5.txt\"\n",
    "#     cut_word_list = cutWords(file_name)\n",
    "#     word_to_index, index_to_word = mapWords(cut_word_list)\n",
    "\n",
    "    SEQ_LENGTH_bits = BitArray(ga_individual_solution[0:3])\n",
    "    SEQ_LENGTH = SEQ_LENGTH_bits.uint+1\n",
    "    \n",
    "    EMBEDDING_DIM_bits = BitArray(ga_individual_solution[3:]) \n",
    "    EMBEDDING_DIM = EMBEDDING_DIM_bits.uint + 1\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = generateTrainData(cut_word_list, word_to_index, SEQ_LENGTH)\n",
    "#     Hidden_size_1_bits = BitArray(ga_individual_solution[8:17]) \n",
    "#     Hidden_size_1 = Hidden_size_1_bits.uint\n",
    "#     Hidden_size_1 = Hidden_size_1+1 if Hidden_size_1==0 else Hidden_size_1\n",
    "    \n",
    "#     Hidden_size_2_bits = BitArray(ga_individual_solution[17:]) \n",
    "#     Hidden_size_2 = Hidden_size_2_bits.uint\n",
    "#     Hidden_size_2 = Hidden_size_2+1 if Hidden_size_2==0 else Hidden_size_2\n",
    "    \n",
    "#     Hidden_size_3_bits = BitArray(ga_individual_solution[26:]) \n",
    "#     Hidden_size_3 = Hidden_size_3_bits.uint\n",
    "#     Hidden_size_3 = Hidden_size_3+1 if Hidden_size_3==0 else Hidden_size_3\n",
    "    \n",
    "    Hidden_size_1 = 512\n",
    "    Hidden_size_2 = 512\n",
    "    Hidden_size_3 = 256\n",
    "    \n",
    "    print('\\nSEQ_LENGTH: ', SEQ_LENGTH, ', EMBEDDING_DIM: ', EMBEDDING_DIM)#, ', Hidden_size_1: ', Hidden_size_1, ', Hidden_size_2 ', Hidden_size_2, ', Hidden_size_3', Hidden_size_3)\n",
    "    \n",
    "    #print(X_train.dtype, y_train.dtype)\n",
    "    nb_words = min(MAX_NB_WORDS, len(word_to_index))\n",
    "    input_shape = (SEQ_LENGTH,)\n",
    "    x_train_in = Input(input_shape, dtype='int32', name=\"x_train\")\n",
    "\n",
    "    # word_index存储的是所有vocabulary的映射关系\n",
    "    embedding_layer = Embedding(nb_words, EMBEDDING_DIM, input_length=SEQ_LENGTH)(x_train_in)\n",
    "    print(\"embedding layer is::\", embedding_layer)\n",
    "    print(\"build model.....\")\n",
    "\n",
    "    # return_sequences=True表示返回的是序列，否则下面的LSTM无法使用，但是如果下一层不是LSTM，则可以不写\n",
    "    lstm_1 = Bidirectional(LSTM(Hidden_size_1, name=\"LSTM_1\", return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(embedding_layer)\n",
    "    #drop_1=Dropout(0.2)(lstm_1)\n",
    "    lstm_2 = Bidirectional(LSTM(Hidden_size_2, name=\"LSTM_2\", return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(lstm_1)#(drop_1)\n",
    "    #drop_2=Dropout(0.2)(lstm_2)\n",
    "    lstm_3 = Bidirectional(LSTM(Hidden_size_3, name=\"LSTM_3\", dropout=0.2, recurrent_dropout=0.2))(lstm_2)#(drop_2)\n",
    "    #drop_3=Dropout(0.2)(lstm_3)\n",
    "    dense = Dense(nb_words, activation=\"softmax\", name=\"Dense_1\")(lstm_3)#(drop_3)\n",
    "\n",
    "    model = Model(inputs=x_train_in, outputs=dense)\n",
    "    #print(model.summary())\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"Train....\")\n",
    "\n",
    "    # save tensorboard info\n",
    "#     tensorboard = TensorBoard(log_dir='./tensorboard_log/')\n",
    "#     # save best model.\n",
    "#     checkpoint = ModelCheckpoint(filepath='./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5',\n",
    "#                                  monitor='val_loss', mode='min', save_best_only=True, save_weights_only=False, period=1, verbose=1)\n",
    "#     reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "#     callback_list = [tensorboard, checkpoint, reduce]\n",
    "\n",
    "    history_record = model.fit(X_train, y_train,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            epochs=EPOCHS\n",
    "                             )\n",
    "    #model.save('./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5')\n",
    "#     evaluate_val = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    print('\\nloss: ', history_record.history['loss'][-1], ', val_loss: ', history_record.history['val_loss'][-1])\n",
    "#     print(model.metrics_names)\n",
    "    del X_train, X_val, y_train, y_val\n",
    "    gc.collect()\n",
    "    del x_train_in, embedding_layer, lstm_1, lstm_2, lstm_3, dense, model\n",
    "    gc.collect()\n",
    "    \n",
    "    loss = history_record.history['loss'][-1]\n",
    "    val_loss = history_record.history['val_loss'][-1]\n",
    "    del history_record\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    return loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEQ_LENGTH:  7 , EMBEDDING_DIM:  74\n",
      "embedding layer is:: Tensor(\"embedding_1/embedding_lookup/Identity:0\", shape=(?, 7, 74), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137200 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137200/137200 [==============================] - 130s 947us/step - loss: 6.3018 - acc: 0.1408 - val_loss: 6.1733 - val_acc: 0.1416\n",
      "Epoch 2/30\n",
      "137200/137200 [==============================] - 120s 874us/step - loss: 6.0328 - acc: 0.1440 - val_loss: 6.0020 - val_acc: 0.1435\n",
      "Epoch 3/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 5.7343 - acc: 0.1539 - val_loss: 5.8251 - val_acc: 0.1559\n",
      "Epoch 4/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 5.4380 - acc: 0.1688 - val_loss: 5.7144 - val_acc: 0.1662\n",
      "Epoch 5/30\n",
      "137200/137200 [==============================] - 120s 874us/step - loss: 5.1826 - acc: 0.1815 - val_loss: 5.6904 - val_acc: 0.1729\n",
      "Epoch 6/30\n",
      "137200/137200 [==============================] - 120s 874us/step - loss: 4.9491 - acc: 0.1934 - val_loss: 5.6833 - val_acc: 0.1768\n",
      "Epoch 7/30\n",
      "137200/137200 [==============================] - 120s 874us/step - loss: 4.7289 - acc: 0.2069 - val_loss: 5.7147 - val_acc: 0.1791\n",
      "Epoch 8/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 4.5202 - acc: 0.2228 - val_loss: 5.7562 - val_acc: 0.1789\n",
      "Epoch 9/30\n",
      "137200/137200 [==============================] - 120s 874us/step - loss: 4.3203 - acc: 0.2413 - val_loss: 5.7746 - val_acc: 0.1778\n",
      "Epoch 10/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 4.1244 - acc: 0.2622 - val_loss: 5.8377 - val_acc: 0.1788\n",
      "Epoch 11/30\n",
      "137200/137200 [==============================] - 122s 888us/step - loss: 3.9335 - acc: 0.2851 - val_loss: 5.8800 - val_acc: 0.1757\n",
      "Epoch 12/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 3.7470 - acc: 0.3105 - val_loss: 5.9465 - val_acc: 0.1789\n",
      "Epoch 13/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 3.5674 - acc: 0.3373 - val_loss: 6.0175 - val_acc: 0.1774\n",
      "Epoch 14/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 3.3965 - acc: 0.3647 - val_loss: 6.0608 - val_acc: 0.1775\n",
      "Epoch 15/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 3.2324 - acc: 0.3915 - val_loss: 6.1322 - val_acc: 0.1762\n",
      "Epoch 16/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 3.0752 - acc: 0.4177 - val_loss: 6.2130 - val_acc: 0.1751\n",
      "Epoch 17/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 2.9293 - acc: 0.4426 - val_loss: 6.2689 - val_acc: 0.1752\n",
      "Epoch 18/30\n",
      "137200/137200 [==============================] - 120s 878us/step - loss: 2.7864 - acc: 0.4666 - val_loss: 6.3561 - val_acc: 0.1704\n",
      "Epoch 19/30\n",
      "137200/137200 [==============================] - 120s 877us/step - loss: 2.6488 - acc: 0.4916 - val_loss: 6.4261 - val_acc: 0.1694\n",
      "Epoch 20/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 2.5251 - acc: 0.5141 - val_loss: 6.4978 - val_acc: 0.1711\n",
      "Epoch 21/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 2.4058 - acc: 0.5350 - val_loss: 6.5702 - val_acc: 0.1688\n",
      "Epoch 22/30\n",
      "137200/137200 [==============================] - 121s 882us/step - loss: 2.2928 - acc: 0.5546 - val_loss: 6.6510 - val_acc: 0.1695\n",
      "Epoch 23/30\n",
      "137200/137200 [==============================] - 121s 882us/step - loss: 2.1878 - acc: 0.5739 - val_loss: 6.6879 - val_acc: 0.1696\n",
      "Epoch 24/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 2.0864 - acc: 0.5926 - val_loss: 6.7830 - val_acc: 0.1703\n",
      "Epoch 25/30\n",
      "137200/137200 [==============================] - 120s 877us/step - loss: 1.9963 - acc: 0.6079 - val_loss: 6.8508 - val_acc: 0.1669\n",
      "Epoch 26/30\n",
      "137200/137200 [==============================] - 121s 879us/step - loss: 1.9074 - acc: 0.6248 - val_loss: 6.9254 - val_acc: 0.1696\n",
      "Epoch 27/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 1.8264 - acc: 0.6383 - val_loss: 6.9859 - val_acc: 0.1698\n",
      "Epoch 28/30\n",
      "137200/137200 [==============================] - 120s 875us/step - loss: 1.7482 - acc: 0.6518 - val_loss: 7.0611 - val_acc: 0.1663\n",
      "Epoch 29/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 1.6747 - acc: 0.6665 - val_loss: 7.1193 - val_acc: 0.1686\n",
      "Epoch 30/30\n",
      "137200/137200 [==============================] - 120s 876us/step - loss: 1.6089 - acc: 0.6780 - val_loss: 7.1856 - val_acc: 0.1656\n",
      "\n",
      "loss:  1.6089082196294044 , val_loss:  7.185605713311631\n",
      "\n",
      "SEQ_LENGTH:  8 , EMBEDDING_DIM:  44\n",
      "embedding layer is:: Tensor(\"embedding_2/embedding_lookup/Identity:0\", shape=(?, 8, 44), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137199 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137199/137199 [==============================] - 140s 1ms/step - loss: 6.3040 - acc: 0.1406 - val_loss: 6.1960 - val_acc: 0.1394\n",
      "Epoch 2/30\n",
      "137199/137199 [==============================] - 133s 968us/step - loss: 6.0808 - acc: 0.1433 - val_loss: 6.0446 - val_acc: 0.1429\n",
      "Epoch 3/30\n",
      "137199/137199 [==============================] - 133s 971us/step - loss: 5.8001 - acc: 0.1514 - val_loss: 5.8573 - val_acc: 0.1553\n",
      "Epoch 4/30\n",
      "137199/137199 [==============================] - 133s 967us/step - loss: 5.5324 - acc: 0.1627 - val_loss: 5.7518 - val_acc: 0.1637\n",
      "Epoch 5/30\n",
      "137199/137199 [==============================] - 133s 967us/step - loss: 5.3096 - acc: 0.1733 - val_loss: 5.7190 - val_acc: 0.1680\n",
      "Epoch 6/30\n",
      "137199/137199 [==============================] - 133s 968us/step - loss: 5.1005 - acc: 0.1840 - val_loss: 5.6991 - val_acc: 0.1745\n",
      "Epoch 7/30\n",
      "137199/137199 [==============================] - 133s 966us/step - loss: 4.9034 - acc: 0.1936 - val_loss: 5.7063 - val_acc: 0.1759\n",
      "Epoch 8/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 4.7153 - acc: 0.2041 - val_loss: 5.7168 - val_acc: 0.1758\n",
      "Epoch 9/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 4.5343 - acc: 0.2177 - val_loss: 5.7510 - val_acc: 0.1784\n",
      "Epoch 10/30\n",
      "137199/137199 [==============================] - 133s 966us/step - loss: 4.3579 - acc: 0.2324 - val_loss: 5.8134 - val_acc: 0.1762\n",
      "Epoch 11/30\n",
      "137199/137199 [==============================] - 132s 965us/step - loss: 4.1854 - acc: 0.2508 - val_loss: 5.8434 - val_acc: 0.1730\n",
      "Epoch 12/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 4.0183 - acc: 0.2697 - val_loss: 5.9049 - val_acc: 0.1747\n",
      "Epoch 13/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 3.8479 - acc: 0.2911 - val_loss: 5.9631 - val_acc: 0.1754\n",
      "Epoch 14/30\n",
      "137199/137199 [==============================] - 133s 972us/step - loss: 3.6856 - acc: 0.3164 - val_loss: 6.0005 - val_acc: 0.1752\n",
      "Epoch 15/30\n",
      "137199/137199 [==============================] - 134s 975us/step - loss: 3.5242 - acc: 0.3403 - val_loss: 6.0767 - val_acc: 0.1778\n",
      "Epoch 16/30\n",
      "137199/137199 [==============================] - 132s 965us/step - loss: 3.3723 - acc: 0.3643 - val_loss: 6.1300 - val_acc: 0.1736\n",
      "Epoch 17/30\n",
      "137199/137199 [==============================] - 133s 968us/step - loss: 3.2271 - acc: 0.3877 - val_loss: 6.1971 - val_acc: 0.1746\n",
      "Epoch 18/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 3.0885 - acc: 0.4127 - val_loss: 6.2459 - val_acc: 0.1721\n",
      "Epoch 19/30\n",
      "137199/137199 [==============================] - 132s 965us/step - loss: 2.9542 - acc: 0.4356 - val_loss: 6.3098 - val_acc: 0.1729\n",
      "Epoch 20/30\n",
      "137199/137199 [==============================] - 132s 965us/step - loss: 2.8268 - acc: 0.4574 - val_loss: 6.3779 - val_acc: 0.1730\n",
      "Epoch 21/30\n",
      "137199/137199 [==============================] - 132s 965us/step - loss: 2.7108 - acc: 0.4766 - val_loss: 6.4347 - val_acc: 0.1683\n",
      "Epoch 22/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 2.5911 - acc: 0.4990 - val_loss: 6.4988 - val_acc: 0.1698\n",
      "Epoch 23/30\n",
      "137199/137199 [==============================] - 132s 966us/step - loss: 2.4855 - acc: 0.5163 - val_loss: 6.5578 - val_acc: 0.1694\n",
      "Epoch 24/30\n",
      "137199/137199 [==============================] - 133s 968us/step - loss: 2.3799 - acc: 0.5358 - val_loss: 6.6356 - val_acc: 0.1688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "137199/137199 [==============================] - 132s 965us/step - loss: 2.2860 - acc: 0.5528 - val_loss: 6.6807 - val_acc: 0.1672\n",
      "Epoch 26/30\n",
      "137199/137199 [==============================] - 132s 965us/step - loss: 2.1902 - acc: 0.5687 - val_loss: 6.7504 - val_acc: 0.1654\n",
      "Epoch 27/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 2.1082 - acc: 0.5846 - val_loss: 6.8067 - val_acc: 0.1642\n",
      "Epoch 28/30\n",
      "137199/137199 [==============================] - 132s 964us/step - loss: 2.0203 - acc: 0.6017 - val_loss: 6.8702 - val_acc: 0.1673\n",
      "Epoch 29/30\n",
      "137199/137199 [==============================] - 132s 962us/step - loss: 1.9488 - acc: 0.6132 - val_loss: 6.9384 - val_acc: 0.1616\n",
      "Epoch 30/30\n",
      "137199/137199 [==============================] - 132s 963us/step - loss: 1.8734 - acc: 0.6260 - val_loss: 6.9936 - val_acc: 0.1644\n",
      "\n",
      "loss:  1.8734254245416622 , val_loss:  6.993621157505114\n",
      "\n",
      "SEQ_LENGTH:  7 , EMBEDDING_DIM:  130\n",
      "embedding layer is:: Tensor(\"embedding_3/embedding_lookup/Identity:0\", shape=(?, 7, 130), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137200 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137200/137200 [==============================] - 129s 944us/step - loss: 6.2897 - acc: 0.1411 - val_loss: 6.1674 - val_acc: 0.1412\n",
      "Epoch 2/30\n",
      "137200/137200 [==============================] - 121s 885us/step - loss: 5.9649 - acc: 0.1459 - val_loss: 5.9592 - val_acc: 0.1477\n",
      "Epoch 3/30\n",
      "137200/137200 [==============================] - 121s 885us/step - loss: 5.6411 - acc: 0.1594 - val_loss: 5.7706 - val_acc: 0.1597\n",
      "Epoch 4/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 5.3498 - acc: 0.1739 - val_loss: 5.6846 - val_acc: 0.1696\n",
      "Epoch 5/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 5.0897 - acc: 0.1878 - val_loss: 5.6609 - val_acc: 0.1754\n",
      "Epoch 6/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 4.8474 - acc: 0.2020 - val_loss: 5.6699 - val_acc: 0.1816\n",
      "Epoch 7/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 4.6177 - acc: 0.2179 - val_loss: 5.6802 - val_acc: 0.1803\n",
      "Epoch 8/30\n",
      "137200/137200 [==============================] - 122s 889us/step - loss: 4.3911 - acc: 0.2377 - val_loss: 5.7229 - val_acc: 0.1839\n",
      "Epoch 9/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 4.1722 - acc: 0.2609 - val_loss: 5.7560 - val_acc: 0.1765\n",
      "Epoch 10/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 3.9558 - acc: 0.2854 - val_loss: 5.8252 - val_acc: 0.1778\n",
      "Epoch 11/30\n",
      "137200/137200 [==============================] - 121s 885us/step - loss: 3.7487 - acc: 0.3137 - val_loss: 5.8898 - val_acc: 0.1745\n",
      "Epoch 12/30\n",
      "137200/137200 [==============================] - 121s 885us/step - loss: 3.5463 - acc: 0.3432 - val_loss: 5.9604 - val_acc: 0.1760\n",
      "Epoch 13/30\n",
      "137200/137200 [==============================] - 121s 885us/step - loss: 3.3504 - acc: 0.3724 - val_loss: 6.0370 - val_acc: 0.1767\n",
      "Epoch 14/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 3.1665 - acc: 0.4018 - val_loss: 6.0934 - val_acc: 0.1741\n",
      "Epoch 15/30\n",
      "137200/137200 [==============================] - 122s 888us/step - loss: 2.9940 - acc: 0.4322 - val_loss: 6.1861 - val_acc: 0.1709\n",
      "Epoch 16/30\n",
      "137200/137200 [==============================] - 122s 887us/step - loss: 2.8286 - acc: 0.4592 - val_loss: 6.2703 - val_acc: 0.1721\n",
      "Epoch 17/30\n",
      "137200/137200 [==============================] - 122s 886us/step - loss: 2.6784 - acc: 0.4849 - val_loss: 6.3420 - val_acc: 0.1694\n",
      "Epoch 18/30\n",
      "137200/137200 [==============================] - 121s 885us/step - loss: 2.5316 - acc: 0.5123 - val_loss: 6.4162 - val_acc: 0.1720\n",
      "Epoch 19/30\n",
      "137200/137200 [==============================] - 121s 885us/step - loss: 2.3982 - acc: 0.5357 - val_loss: 6.4910 - val_acc: 0.1693\n",
      "Epoch 20/30\n",
      "137200/137200 [==============================] - 123s 899us/step - loss: 2.2726 - acc: 0.5568 - val_loss: 6.5680 - val_acc: 0.1660\n",
      "Epoch 21/30\n",
      "137200/137200 [==============================] - 122s 892us/step - loss: 2.1578 - acc: 0.5771 - val_loss: 6.6351 - val_acc: 0.1670\n",
      "Epoch 22/30\n",
      "137200/137200 [==============================] - 123s 893us/step - loss: 2.0455 - acc: 0.5975 - val_loss: 6.7237 - val_acc: 0.1637\n",
      "Epoch 23/30\n",
      "137200/137200 [==============================] - 123s 895us/step - loss: 1.9423 - acc: 0.6160 - val_loss: 6.7931 - val_acc: 0.1637\n",
      "Epoch 24/30\n",
      "137200/137200 [==============================] - 123s 893us/step - loss: 1.8447 - acc: 0.6340 - val_loss: 6.8603 - val_acc: 0.1677\n",
      "Epoch 25/30\n",
      "137200/137200 [==============================] - 122s 892us/step - loss: 1.7592 - acc: 0.6483 - val_loss: 6.9303 - val_acc: 0.1673\n",
      "Epoch 26/30\n",
      "137200/137200 [==============================] - 122s 892us/step - loss: 1.6723 - acc: 0.6656 - val_loss: 6.9961 - val_acc: 0.1640\n",
      "Epoch 27/30\n",
      "137200/137200 [==============================] - 122s 892us/step - loss: 1.5927 - acc: 0.6802 - val_loss: 7.0639 - val_acc: 0.1668\n",
      "Epoch 28/30\n",
      "137200/137200 [==============================] - 122s 892us/step - loss: 1.5213 - acc: 0.6919 - val_loss: 7.1351 - val_acc: 0.1679\n",
      "Epoch 29/30\n",
      "137200/137200 [==============================] - 122s 893us/step - loss: 1.4505 - acc: 0.7058 - val_loss: 7.2123 - val_acc: 0.1654\n",
      "Epoch 30/30\n",
      "137200/137200 [==============================] - 123s 896us/step - loss: 1.3857 - acc: 0.7174 - val_loss: 7.2711 - val_acc: 0.1699\n",
      "\n",
      "loss:  1.3856628734516332 , val_loss:  7.271111948242263\n",
      "\n",
      "SEQ_LENGTH:  7 , EMBEDDING_DIM:  229\n",
      "embedding layer is:: Tensor(\"embedding_4/embedding_lookup/Identity:0\", shape=(?, 7, 229), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137200 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137200/137200 [==============================] - 133s 971us/step - loss: 6.2822 - acc: 0.1412 - val_loss: 6.1902 - val_acc: 0.1399\n",
      "Epoch 2/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 6.0668 - acc: 0.1441 - val_loss: 6.0489 - val_acc: 0.1441\n",
      "Epoch 3/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 5.7698 - acc: 0.1533 - val_loss: 5.8592 - val_acc: 0.1539\n",
      "Epoch 4/30\n",
      "137200/137200 [==============================] - 124s 907us/step - loss: 5.4770 - acc: 0.1674 - val_loss: 5.7605 - val_acc: 0.1651\n",
      "Epoch 5/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 5.2231 - acc: 0.1817 - val_loss: 5.7080 - val_acc: 0.1715\n",
      "Epoch 6/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 4.9925 - acc: 0.1948 - val_loss: 5.7006 - val_acc: 0.1733\n",
      "Epoch 7/30\n",
      "137200/137200 [==============================] - 124s 906us/step - loss: 4.7751 - acc: 0.2084 - val_loss: 5.7101 - val_acc: 0.1829\n",
      "Epoch 8/30\n",
      "137200/137200 [==============================] - 124s 905us/step - loss: 4.5671 - acc: 0.2236 - val_loss: 5.7447 - val_acc: 0.1795\n",
      "Epoch 9/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 4.3635 - acc: 0.2432 - val_loss: 5.7968 - val_acc: 0.1794\n",
      "Epoch 10/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 4.1688 - acc: 0.2618 - val_loss: 5.8393 - val_acc: 0.1810\n",
      "Epoch 11/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 3.9741 - acc: 0.2844 - val_loss: 5.9002 - val_acc: 0.1743\n",
      "Epoch 12/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 3.7880 - acc: 0.3086 - val_loss: 5.9674 - val_acc: 0.1752\n",
      "Epoch 13/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 3.6050 - acc: 0.3353 - val_loss: 6.0455 - val_acc: 0.1726\n",
      "Epoch 14/30\n",
      "137200/137200 [==============================] - 124s 906us/step - loss: 3.4225 - acc: 0.3630 - val_loss: 6.1095 - val_acc: 0.1674\n",
      "Epoch 15/30\n",
      "137200/137200 [==============================] - 124s 905us/step - loss: 3.2543 - acc: 0.3892 - val_loss: 6.1977 - val_acc: 0.1736\n",
      "Epoch 16/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 3.0856 - acc: 0.4159 - val_loss: 6.2594 - val_acc: 0.1673\n",
      "Epoch 17/30\n",
      "137200/137200 [==============================] - 124s 905us/step - loss: 2.9313 - acc: 0.4426 - val_loss: 6.3436 - val_acc: 0.1711\n",
      "Epoch 18/30\n",
      "137200/137200 [==============================] - 124s 904us/step - loss: 2.7825 - acc: 0.4679 - val_loss: 6.4056 - val_acc: 0.1648\n",
      "Epoch 19/30\n",
      "137200/137200 [==============================] - 127s 924us/step - loss: 2.6416 - acc: 0.4929 - val_loss: 6.4901 - val_acc: 0.1685\n",
      "Epoch 20/30\n",
      "137200/137200 [==============================] - 125s 909us/step - loss: 2.5064 - acc: 0.5157 - val_loss: 6.5587 - val_acc: 0.1652\n",
      "Epoch 21/30\n",
      "137200/137200 [==============================] - 125s 910us/step - loss: 2.3806 - acc: 0.5386 - val_loss: 6.6286 - val_acc: 0.1684\n",
      "Epoch 22/30\n",
      "137200/137200 [==============================] - 125s 910us/step - loss: 2.2668 - acc: 0.5582 - val_loss: 6.6959 - val_acc: 0.1631\n",
      "Epoch 23/30\n",
      "137200/137200 [==============================] - 125s 909us/step - loss: 2.1572 - acc: 0.5778 - val_loss: 6.7768 - val_acc: 0.1669\n",
      "Epoch 24/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 2.0483 - acc: 0.5965 - val_loss: 6.8438 - val_acc: 0.1667\n",
      "Epoch 25/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 1.9533 - acc: 0.6140 - val_loss: 6.9121 - val_acc: 0.1668\n",
      "Epoch 26/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 1.8583 - acc: 0.6301 - val_loss: 6.9860 - val_acc: 0.1681\n",
      "Epoch 27/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 1.7733 - acc: 0.6472 - val_loss: 7.0572 - val_acc: 0.1635\n",
      "Epoch 28/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 1.6921 - acc: 0.6615 - val_loss: 7.0955 - val_acc: 0.1648\n",
      "Epoch 29/30\n",
      "137200/137200 [==============================] - 125s 911us/step - loss: 1.6138 - acc: 0.6760 - val_loss: 7.1662 - val_acc: 0.1623\n",
      "Epoch 30/30\n",
      "137200/137200 [==============================] - 125s 908us/step - loss: 1.5409 - acc: 0.6887 - val_loss: 7.2294 - val_acc: 0.1652\n",
      "\n",
      "loss:  1.5409470944362895 , val_loss:  7.229372412722867\n",
      "\n",
      "SEQ_LENGTH:  6 , EMBEDDING_DIM:  132\n",
      "embedding layer is:: Tensor(\"embedding_5/embedding_lookup/Identity:0\", shape=(?, 6, 132), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137201 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137201/137201 [==============================] - 118s 860us/step - loss: 6.2930 - acc: 0.1406 - val_loss: 6.1596 - val_acc: 0.1391\n",
      "Epoch 2/30\n",
      "137201/137201 [==============================] - 109s 791us/step - loss: 5.9392 - acc: 0.1469 - val_loss: 5.9074 - val_acc: 0.1505\n",
      "Epoch 3/30\n",
      "137201/137201 [==============================] - 109s 792us/step - loss: 5.5701 - acc: 0.1625 - val_loss: 5.7454 - val_acc: 0.1641\n",
      "Epoch 4/30\n",
      "137201/137201 [==============================] - 108s 788us/step - loss: 5.2355 - acc: 0.1799 - val_loss: 5.6967 - val_acc: 0.1718\n",
      "Epoch 5/30\n",
      "137201/137201 [==============================] - 108s 788us/step - loss: 4.9217 - acc: 0.1980 - val_loss: 5.6844 - val_acc: 0.1757\n",
      "Epoch 6/30\n",
      "137201/137201 [==============================] - 111s 808us/step - loss: 4.6201 - acc: 0.2206 - val_loss: 5.7138 - val_acc: 0.1808\n",
      "Epoch 7/30\n",
      "137201/137201 [==============================] - 109s 794us/step - loss: 4.3293 - acc: 0.2463 - val_loss: 5.7558 - val_acc: 0.1768\n",
      "Epoch 8/30\n",
      "137201/137201 [==============================] - 109s 794us/step - loss: 4.0460 - acc: 0.2785 - val_loss: 5.8086 - val_acc: 0.1775\n",
      "Epoch 9/30\n",
      "137201/137201 [==============================] - 109s 796us/step - loss: 3.7789 - acc: 0.3147 - val_loss: 5.8865 - val_acc: 0.1773\n",
      "Epoch 10/30\n",
      "137201/137201 [==============================] - 109s 792us/step - loss: 3.5248 - acc: 0.3517 - val_loss: 5.9568 - val_acc: 0.1730\n",
      "Epoch 11/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 3.2916 - acc: 0.3889 - val_loss: 6.0072 - val_acc: 0.1744\n",
      "Epoch 12/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 3.0749 - acc: 0.4248 - val_loss: 6.0872 - val_acc: 0.1733\n",
      "Epoch 13/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 2.8757 - acc: 0.4586 - val_loss: 6.1726 - val_acc: 0.1745\n",
      "Epoch 14/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 2.6921 - acc: 0.4913 - val_loss: 6.2532 - val_acc: 0.1715\n",
      "Epoch 15/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 2.5221 - acc: 0.5181 - val_loss: 6.3561 - val_acc: 0.1725\n",
      "Epoch 16/30\n",
      "137201/137201 [==============================] - 109s 792us/step - loss: 2.3683 - acc: 0.5455 - val_loss: 6.4415 - val_acc: 0.1700\n",
      "Epoch 17/30\n",
      "137201/137201 [==============================] - 109s 796us/step - loss: 2.2259 - acc: 0.5706 - val_loss: 6.5093 - val_acc: 0.1700\n",
      "Epoch 18/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 2.0915 - acc: 0.5940 - val_loss: 6.6241 - val_acc: 0.1709\n",
      "Epoch 19/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 1.9698 - acc: 0.6161 - val_loss: 6.7003 - val_acc: 0.1711\n",
      "Epoch 20/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 1.8573 - acc: 0.6359 - val_loss: 6.7885 - val_acc: 0.1671\n",
      "Epoch 21/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 1.7545 - acc: 0.6552 - val_loss: 6.8597 - val_acc: 0.1662\n",
      "Epoch 22/30\n",
      "137201/137201 [==============================] - 109s 793us/step - loss: 1.6606 - acc: 0.6706 - val_loss: 6.9515 - val_acc: 0.1690\n",
      "Epoch 23/30\n",
      "137201/137201 [==============================] - 108s 789us/step - loss: 1.5663 - acc: 0.6894 - val_loss: 7.0370 - val_acc: 0.1677\n",
      "Epoch 24/30\n",
      "137201/137201 [==============================] - 108s 789us/step - loss: 1.4823 - acc: 0.7051 - val_loss: 7.1461 - val_acc: 0.1709\n",
      "Epoch 25/30\n",
      "137201/137201 [==============================] - 109s 792us/step - loss: 1.4045 - acc: 0.7187 - val_loss: 7.2027 - val_acc: 0.1718\n",
      "Epoch 26/30\n",
      "137201/137201 [==============================] - 109s 791us/step - loss: 1.3381 - acc: 0.7304 - val_loss: 7.2745 - val_acc: 0.1711\n",
      "Epoch 27/30\n",
      "137201/137201 [==============================] - 108s 790us/step - loss: 1.2654 - acc: 0.7445 - val_loss: 7.3605 - val_acc: 0.1675\n",
      "Epoch 28/30\n",
      "137201/137201 [==============================] - 108s 790us/step - loss: 1.2068 - acc: 0.7545 - val_loss: 7.4373 - val_acc: 0.1698\n",
      "Epoch 29/30\n",
      "137201/137201 [==============================] - 108s 790us/step - loss: 1.1458 - acc: 0.7652 - val_loss: 7.5249 - val_acc: 0.1741\n",
      "Epoch 30/30\n",
      "137201/137201 [==============================] - 108s 790us/step - loss: 1.0950 - acc: 0.7733 - val_loss: 7.5987 - val_acc: 0.1706\n",
      "\n",
      "loss:  1.0949840769491566 , val_loss:  7.598666369504481\n",
      "\n",
      "SEQ_LENGTH:  2 , EMBEDDING_DIM:  120\n",
      "embedding layer is:: Tensor(\"embedding_6/embedding_lookup/Identity:0\", shape=(?, 2, 120), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 63s 462us/step - loss: 6.3268 - acc: 0.1397 - val_loss: 6.1668 - val_acc: 0.1381\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 53s 389us/step - loss: 5.9387 - acc: 0.1477 - val_loss: 5.9073 - val_acc: 0.1515\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 53s 389us/step - loss: 5.5892 - acc: 0.1651 - val_loss: 5.7514 - val_acc: 0.1615\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 53s 389us/step - loss: 5.2818 - acc: 0.1809 - val_loss: 5.6934 - val_acc: 0.1700\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 53s 389us/step - loss: 5.0009 - acc: 0.1939 - val_loss: 5.6764 - val_acc: 0.1717\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 54s 392us/step - loss: 4.7292 - acc: 0.2086 - val_loss: 5.6824 - val_acc: 0.1753\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 54s 390us/step - loss: 4.4789 - acc: 0.2237 - val_loss: 5.7312 - val_acc: 0.1777\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 53s 390us/step - loss: 4.2512 - acc: 0.2391 - val_loss: 5.7717 - val_acc: 0.1782\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 53s 389us/step - loss: 4.0405 - acc: 0.2559 - val_loss: 5.8169 - val_acc: 0.1778\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 53s 390us/step - loss: 3.8547 - acc: 0.2717 - val_loss: 5.8754 - val_acc: 0.1772\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137205/137205 [==============================] - 53s 388us/step - loss: 3.6798 - acc: 0.2879 - val_loss: 5.9350 - val_acc: 0.1757\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 3.5223 - acc: 0.3044 - val_loss: 5.9832 - val_acc: 0.1761\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 3.3783 - acc: 0.3206 - val_loss: 6.0526 - val_acc: 0.1705\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 3.2474 - acc: 0.3355 - val_loss: 6.1117 - val_acc: 0.1739\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 3.1280 - acc: 0.3481 - val_loss: 6.1703 - val_acc: 0.1705\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 3.0154 - acc: 0.3620 - val_loss: 6.2443 - val_acc: 0.1677\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.9190 - acc: 0.3735 - val_loss: 6.2889 - val_acc: 0.1708\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.8203 - acc: 0.3853 - val_loss: 6.3642 - val_acc: 0.1669\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.7400 - acc: 0.3951 - val_loss: 6.3948 - val_acc: 0.1701\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.6594 - acc: 0.4045 - val_loss: 6.4758 - val_acc: 0.1617\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.5889 - acc: 0.4144 - val_loss: 6.5329 - val_acc: 0.1646\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 53s 389us/step - loss: 2.5296 - acc: 0.4204 - val_loss: 6.5998 - val_acc: 0.1648\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 54s 392us/step - loss: 2.4659 - acc: 0.4297 - val_loss: 6.6543 - val_acc: 0.1601\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 53s 390us/step - loss: 2.4121 - acc: 0.4352 - val_loss: 6.7014 - val_acc: 0.1641\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.3626 - acc: 0.4425 - val_loss: 6.7539 - val_acc: 0.1647\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.3197 - acc: 0.4476 - val_loss: 6.8078 - val_acc: 0.1629\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.2772 - acc: 0.4535 - val_loss: 6.8556 - val_acc: 0.1621\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.2391 - acc: 0.4575 - val_loss: 6.9140 - val_acc: 0.1593\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.1993 - acc: 0.4623 - val_loss: 6.9528 - val_acc: 0.1602\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.1700 - acc: 0.4656 - val_loss: 7.0019 - val_acc: 0.1589\n",
      "\n",
      "loss:  2.1699892168954547 , val_loss:  7.001917962145907\n",
      "\n",
      "SEQ_LENGTH:  1 , EMBEDDING_DIM:  152\n",
      "embedding layer is:: Tensor(\"embedding_7/embedding_lookup/Identity:0\", shape=(?, 1, 152), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15246 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 50s 366us/step - loss: 6.3712 - acc: 0.1393 - val_loss: 6.2396 - val_acc: 0.1335\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 39s 288us/step - loss: 6.1207 - acc: 0.1407 - val_loss: 6.0726 - val_acc: 0.1374\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 5.8770 - acc: 0.1481 - val_loss: 5.9101 - val_acc: 0.1478\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 5.6502 - acc: 0.1569 - val_loss: 5.8043 - val_acc: 0.1535\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 5.4396 - acc: 0.1639 - val_loss: 5.7392 - val_acc: 0.1598\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 40s 289us/step - loss: 5.2367 - acc: 0.1708 - val_loss: 5.7068 - val_acc: 0.1623\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 40s 289us/step - loss: 5.0651 - acc: 0.1763 - val_loss: 5.6795 - val_acc: 0.1657\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 40s 289us/step - loss: 4.9253 - acc: 0.1800 - val_loss: 5.6757 - val_acc: 0.1633\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 40s 289us/step - loss: 4.8111 - acc: 0.1823 - val_loss: 5.6715 - val_acc: 0.1665\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 40s 289us/step - loss: 4.7179 - acc: 0.1849 - val_loss: 5.6727 - val_acc: 0.1677\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 40s 289us/step - loss: 4.6381 - acc: 0.1858 - val_loss: 5.6936 - val_acc: 0.1680\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 40s 291us/step - loss: 4.5704 - acc: 0.1877 - val_loss: 5.7139 - val_acc: 0.1661\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 40s 291us/step - loss: 4.5125 - acc: 0.1890 - val_loss: 5.7186 - val_acc: 0.1684\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 4.4615 - acc: 0.1899 - val_loss: 5.7378 - val_acc: 0.1687\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 4.4173 - acc: 0.1901 - val_loss: 5.7515 - val_acc: 0.1677\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 40s 289us/step - loss: 4.3777 - acc: 0.1902 - val_loss: 5.7758 - val_acc: 0.1663\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 4.3420 - acc: 0.1914 - val_loss: 5.7868 - val_acc: 0.1690\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 39s 288us/step - loss: 4.3119 - acc: 0.1911 - val_loss: 5.8051 - val_acc: 0.1678\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 4.2823 - acc: 0.1922 - val_loss: 5.8252 - val_acc: 0.1632\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 4.2552 - acc: 0.1928 - val_loss: 5.8572 - val_acc: 0.1666\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 40s 288us/step - loss: 4.2318 - acc: 0.1928 - val_loss: 5.8623 - val_acc: 0.1673\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 42s 306us/step - loss: 4.2126 - acc: 0.1921 - val_loss: 5.8866 - val_acc: 0.1664\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 40s 295us/step - loss: 4.1926 - acc: 0.1933 - val_loss: 5.9032 - val_acc: 0.1662\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1723 - acc: 0.1941 - val_loss: 5.9183 - val_acc: 0.1650\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1571 - acc: 0.1939 - val_loss: 5.9337 - val_acc: 0.1621\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 40s 292us/step - loss: 4.1432 - acc: 0.1931 - val_loss: 5.9354 - val_acc: 0.1667\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1285 - acc: 0.1932 - val_loss: 5.9530 - val_acc: 0.1713\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1139 - acc: 0.1940 - val_loss: 5.9794 - val_acc: 0.1681\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1024 - acc: 0.1947 - val_loss: 5.9938 - val_acc: 0.1658\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.0917 - acc: 0.1943 - val_loss: 6.0026 - val_acc: 0.1674\n",
      "\n",
      "loss:  4.091650811084822 , val_loss:  6.002639337332249\n",
      "\n",
      "SEQ_LENGTH:  6 , EMBEDDING_DIM:  249\n",
      "embedding layer is:: Tensor(\"embedding_8/embedding_lookup/Identity:0\", shape=(?, 6, 249), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137201 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137201/137201 [==============================] - 123s 896us/step - loss: 6.2859 - acc: 0.1406 - val_loss: 6.1514 - val_acc: 0.1386\n",
      "Epoch 2/30\n",
      "137201/137201 [==============================] - 111s 812us/step - loss: 5.9018 - acc: 0.1476 - val_loss: 5.8818 - val_acc: 0.1504\n",
      "Epoch 3/30\n",
      "137201/137201 [==============================] - 111s 810us/step - loss: 5.4985 - acc: 0.1673 - val_loss: 5.7130 - val_acc: 0.1698\n",
      "Epoch 4/30\n",
      "137201/137201 [==============================] - 111s 809us/step - loss: 5.1285 - acc: 0.1888 - val_loss: 5.6518 - val_acc: 0.1756\n",
      "Epoch 5/30\n",
      "137201/137201 [==============================] - 111s 808us/step - loss: 4.7923 - acc: 0.2110 - val_loss: 5.6601 - val_acc: 0.1780\n",
      "Epoch 6/30\n",
      "137201/137201 [==============================] - 111s 809us/step - loss: 4.4768 - acc: 0.2360 - val_loss: 5.6844 - val_acc: 0.1806\n",
      "Epoch 7/30\n",
      "137201/137201 [==============================] - 111s 809us/step - loss: 4.1685 - acc: 0.2665 - val_loss: 5.7315 - val_acc: 0.1763\n",
      "Epoch 8/30\n",
      "137201/137201 [==============================] - 111s 809us/step - loss: 3.8694 - acc: 0.3014 - val_loss: 5.8116 - val_acc: 0.1761\n",
      "Epoch 9/30\n",
      "137201/137201 [==============================] - 111s 809us/step - loss: 3.5834 - acc: 0.3412 - val_loss: 5.8866 - val_acc: 0.1722\n",
      "Epoch 10/30\n",
      "137201/137201 [==============================] - 111s 811us/step - loss: 3.3152 - acc: 0.3824 - val_loss: 5.9679 - val_acc: 0.1709\n",
      "Epoch 11/30\n",
      "137201/137201 [==============================] - 111s 810us/step - loss: 3.0643 - acc: 0.4241 - val_loss: 6.0580 - val_acc: 0.1704\n",
      "Epoch 12/30\n",
      "137201/137201 [==============================] - 111s 810us/step - loss: 2.8350 - acc: 0.4628 - val_loss: 6.1533 - val_acc: 0.1692\n",
      "Epoch 13/30\n",
      "137201/137201 [==============================] - 111s 809us/step - loss: 2.6207 - acc: 0.4985 - val_loss: 6.2304 - val_acc: 0.1726\n",
      "Epoch 14/30\n",
      "137201/137201 [==============================] - 111s 807us/step - loss: 2.4263 - acc: 0.5326 - val_loss: 6.3486 - val_acc: 0.1679\n",
      "Epoch 15/30\n",
      "137201/137201 [==============================] - 111s 806us/step - loss: 2.2486 - acc: 0.5634 - val_loss: 6.4399 - val_acc: 0.1701\n",
      "Epoch 16/30\n",
      "137201/137201 [==============================] - 111s 805us/step - loss: 2.0855 - acc: 0.5924 - val_loss: 6.5332 - val_acc: 0.1660\n",
      "Epoch 17/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 1.9384 - acc: 0.6181 - val_loss: 6.6331 - val_acc: 0.1664\n",
      "Epoch 18/30\n",
      "137201/137201 [==============================] - 111s 807us/step - loss: 1.8004 - acc: 0.6448 - val_loss: 6.7374 - val_acc: 0.1637\n",
      "Epoch 19/30\n",
      "137201/137201 [==============================] - 111s 807us/step - loss: 1.6723 - acc: 0.6664 - val_loss: 6.8242 - val_acc: 0.1704- loss: 1.\n",
      "Epoch 20/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 1.5594 - acc: 0.6874 - val_loss: 6.9184 - val_acc: 0.1690\n",
      "Epoch 21/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 1.4498 - acc: 0.7088 - val_loss: 7.0287 - val_acc: 0.1679\n",
      "Epoch 22/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 1.3544 - acc: 0.7263 - val_loss: 7.1323 - val_acc: 0.1671\n",
      "Epoch 23/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 1.2597 - acc: 0.7441 - val_loss: 7.2311 - val_acc: 0.1698\n",
      "Epoch 24/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 1.1846 - acc: 0.7558 - val_loss: 7.2863 - val_acc: 0.1677\n",
      "Epoch 25/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 1.1104 - acc: 0.7702 - val_loss: 7.3796 - val_acc: 0.1695\n",
      "Epoch 26/30\n",
      "137201/137201 [==============================] - 111s 806us/step - loss: 1.0412 - acc: 0.7830 - val_loss: 7.4591 - val_acc: 0.1625\n",
      "Epoch 27/30\n",
      "137201/137201 [==============================] - 111s 807us/step - loss: 0.9775 - acc: 0.7952 - val_loss: 7.5417 - val_acc: 0.1701\n",
      "Epoch 28/30\n",
      "137201/137201 [==============================] - 110s 804us/step - loss: 0.9185 - acc: 0.8069 - val_loss: 7.6095 - val_acc: 0.1728\n",
      "Epoch 29/30\n",
      "137201/137201 [==============================] - 111s 806us/step - loss: 0.8673 - acc: 0.8143 - val_loss: 7.6854 - val_acc: 0.1683\n",
      "Epoch 30/30\n",
      "137201/137201 [==============================] - 110s 805us/step - loss: 0.8170 - acc: 0.8243 - val_loss: 7.7472 - val_acc: 0.1656\n",
      "\n",
      "loss:  0.8170366758287169 , val_loss:  7.747190643533718\n",
      "\n",
      "SEQ_LENGTH:  2 , EMBEDDING_DIM:  31\n",
      "embedding layer is:: Tensor(\"embedding_9/embedding_lookup/Identity:0\", shape=(?, 2, 31), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 65s 470us/step - loss: 6.3574 - acc: 0.1394 - val_loss: 6.2332 - val_acc: 0.1375\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 52s 379us/step - loss: 6.0639 - acc: 0.1432 - val_loss: 5.9980 - val_acc: 0.1454\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 52s 379us/step - loss: 5.7536 - acc: 0.1545 - val_loss: 5.8459 - val_acc: 0.1551\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 52s 379us/step - loss: 5.4919 - acc: 0.1668 - val_loss: 5.7593 - val_acc: 0.1613\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 5.2497 - acc: 0.1770 - val_loss: 5.7152 - val_acc: 0.1671\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 5.0166 - acc: 0.1880 - val_loss: 5.7136 - val_acc: 0.1717\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 4.7950 - acc: 0.1992 - val_loss: 5.7427 - val_acc: 0.1722\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 52s 381us/step - loss: 4.5935 - acc: 0.2090 - val_loss: 5.7671 - val_acc: 0.1751\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 53s 383us/step - loss: 4.4114 - acc: 0.2206 - val_loss: 5.7884 - val_acc: 0.1768\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 4.2435 - acc: 0.2307 - val_loss: 5.8546 - val_acc: 0.1756\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 4.0873 - acc: 0.2426 - val_loss: 5.8772 - val_acc: 0.1740\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 52s 379us/step - loss: 3.9444 - acc: 0.2557 - val_loss: 5.9198 - val_acc: 0.1721\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 3.8105 - acc: 0.2673 - val_loss: 5.9816 - val_acc: 0.1717\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 3.6902 - acc: 0.2779 - val_loss: 6.0190 - val_acc: 0.1761\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 3.5762 - acc: 0.2898 - val_loss: 6.0703 - val_acc: 0.1713\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 3.4669 - acc: 0.3012 - val_loss: 6.1243 - val_acc: 0.1708\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 3.3654 - acc: 0.3112 - val_loss: 6.1672 - val_acc: 0.1693\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 52s 379us/step - loss: 3.2779 - acc: 0.3215 - val_loss: 6.2260 - val_acc: 0.1696\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 52s 380us/step - loss: 3.1894 - acc: 0.3309 - val_loss: 6.2715 - val_acc: 0.1692\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 54s 390us/step - loss: 3.1069 - acc: 0.3413 - val_loss: 6.3246 - val_acc: 0.1642\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 54s 395us/step - loss: 3.0312 - acc: 0.3500 - val_loss: 6.3654 - val_acc: 0.1672\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 53s 386us/step - loss: 2.9593 - acc: 0.3580 - val_loss: 6.4127 - val_acc: 0.1654\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.8926 - acc: 0.3660 - val_loss: 6.4641 - val_acc: 0.1676\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 53s 386us/step - loss: 2.8292 - acc: 0.3758 - val_loss: 6.5179 - val_acc: 0.1672\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 53s 386us/step - loss: 2.7718 - acc: 0.3816 - val_loss: 6.5577 - val_acc: 0.1637\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 53s 389us/step - loss: 2.7149 - acc: 0.3880 - val_loss: 6.5934 - val_acc: 0.1601\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 53s 386us/step - loss: 2.6630 - acc: 0.3960 - val_loss: 6.6473 - val_acc: 0.1654\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 53s 385us/step - loss: 2.6146 - acc: 0.4033 - val_loss: 6.7012 - val_acc: 0.1598\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137205/137205 [==============================] - 53s 384us/step - loss: 2.5678 - acc: 0.4078 - val_loss: 6.7471 - val_acc: 0.1610\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 2.5287 - acc: 0.4126 - val_loss: 6.7921 - val_acc: 0.1585\n",
      "\n",
      "loss:  2.52865066091641 , val_loss:  6.79207150839946\n",
      "\n",
      "SEQ_LENGTH:  1 , EMBEDDING_DIM:  119\n",
      "embedding layer is:: Tensor(\"embedding_10/embedding_lookup/Identity:0\", shape=(?, 1, 119), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15246 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 54s 391us/step - loss: 6.3753 - acc: 0.1392 - val_loss: 6.2736 - val_acc: 0.1345\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 6.1450 - acc: 0.1397 - val_loss: 6.1129 - val_acc: 0.1351\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.9404 - acc: 0.1441 - val_loss: 5.9605 - val_acc: 0.1440\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.7173 - acc: 0.1530 - val_loss: 5.8517 - val_acc: 0.1534\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.5027 - acc: 0.1609 - val_loss: 5.7592 - val_acc: 0.1555\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.2927 - acc: 0.1691 - val_loss: 5.7046 - val_acc: 0.1603\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.1047 - acc: 0.1743 - val_loss: 5.6826 - val_acc: 0.1608\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.9503 - acc: 0.1790 - val_loss: 5.6736 - val_acc: 0.1660\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.8266 - acc: 0.1822 - val_loss: 5.6683 - val_acc: 0.1669\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.7258 - acc: 0.1843 - val_loss: 5.6759 - val_acc: 0.1702\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.6422 - acc: 0.1859 - val_loss: 5.6766 - val_acc: 0.1677\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.5732 - acc: 0.1877 - val_loss: 5.6958 - val_acc: 0.1721\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.5135 - acc: 0.1888 - val_loss: 5.7056 - val_acc: 0.1661\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.4636 - acc: 0.1889 - val_loss: 5.7238 - val_acc: 0.1673\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.4173 - acc: 0.1912 - val_loss: 5.7453 - val_acc: 0.1665\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.3780 - acc: 0.1909 - val_loss: 5.7661 - val_acc: 0.1682\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 41s 295us/step - loss: 4.3440 - acc: 0.1912 - val_loss: 5.7782 - val_acc: 0.1703\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 40s 295us/step - loss: 4.3114 - acc: 0.1924 - val_loss: 5.8045 - val_acc: 0.1683\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.2831 - acc: 0.1938 - val_loss: 5.8203 - val_acc: 0.1675\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 40s 295us/step - loss: 4.2599 - acc: 0.1923 - val_loss: 5.8395 - val_acc: 0.1666\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.2347 - acc: 0.1923 - val_loss: 5.8458 - val_acc: 0.1686\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.2126 - acc: 0.1930 - val_loss: 5.8675 - val_acc: 0.1670\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.1965 - acc: 0.1930 - val_loss: 5.8856 - val_acc: 0.1649\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.1765 - acc: 0.1930 - val_loss: 5.8936 - val_acc: 0.1680\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.1609 - acc: 0.1939 - val_loss: 5.9187 - val_acc: 0.1659\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.1450 - acc: 0.1940 - val_loss: 5.9286 - val_acc: 0.1654\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1324 - acc: 0.1942 - val_loss: 5.9557 - val_acc: 0.1667\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1188 - acc: 0.1933 - val_loss: 5.9692 - val_acc: 0.1678\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1073 - acc: 0.1938 - val_loss: 5.9799 - val_acc: 0.1638\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.0965 - acc: 0.1939 - val_loss: 5.9908 - val_acc: 0.1669\n",
      "\n",
      "loss:  4.09645114433122 , val_loss:  5.990752801328417\n",
      "\n",
      "SEQ_LENGTH:  2 , EMBEDDING_DIM:  31\n",
      "embedding layer is:: Tensor(\"embedding_11/embedding_lookup/Identity:0\", shape=(?, 2, 31), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 67s 490us/step - loss: 6.3441 - acc: 0.1393 - val_loss: 6.2215 - val_acc: 0.1372\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 6.0378 - acc: 0.1440 - val_loss: 5.9762 - val_acc: 0.1469\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 5.7383 - acc: 0.1541 - val_loss: 5.8281 - val_acc: 0.1558\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 5.4828 - acc: 0.1677 - val_loss: 5.7415 - val_acc: 0.1631\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 5.2438 - acc: 0.1775 - val_loss: 5.7105 - val_acc: 0.1673\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 5.0181 - acc: 0.1871 - val_loss: 5.7060 - val_acc: 0.1700\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 53s 385us/step - loss: 4.8079 - acc: 0.1974 - val_loss: 5.7452 - val_acc: 0.1700\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 4.6128 - acc: 0.2076 - val_loss: 5.7496 - val_acc: 0.1754\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 4.4317 - acc: 0.2181 - val_loss: 5.7948 - val_acc: 0.1730\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 4.2707 - acc: 0.2289 - val_loss: 5.8248 - val_acc: 0.1768\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 4.1190 - acc: 0.2398 - val_loss: 5.8654 - val_acc: 0.1772\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 53s 385us/step - loss: 3.9774 - acc: 0.2514 - val_loss: 5.9083 - val_acc: 0.1765\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.8461 - acc: 0.2626 - val_loss: 5.9416 - val_acc: 0.1711\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 53s 385us/step - loss: 3.7263 - acc: 0.2729 - val_loss: 5.9964 - val_acc: 0.1746\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.6119 - acc: 0.2851 - val_loss: 6.0433 - val_acc: 0.1740\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.5053 - acc: 0.2960 - val_loss: 6.0808 - val_acc: 0.1742\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.4066 - acc: 0.3068 - val_loss: 6.1238 - val_acc: 0.1711\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.3163 - acc: 0.3168 - val_loss: 6.1833 - val_acc: 0.1687\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.2269 - acc: 0.3265 - val_loss: 6.2300 - val_acc: 0.1684\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.1468 - acc: 0.3360 - val_loss: 6.2710 - val_acc: 0.1707\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 53s 384us/step - loss: 3.0695 - acc: 0.3450 - val_loss: 6.3200 - val_acc: 0.1683\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 54s 392us/step - loss: 2.9990 - acc: 0.3537 - val_loss: 6.3658 - val_acc: 0.1673\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137205/137205 [==============================] - 54s 396us/step - loss: 2.9293 - acc: 0.3615 - val_loss: 6.4095 - val_acc: 0.1694\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.8664 - acc: 0.3707 - val_loss: 6.4644 - val_acc: 0.1625\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.8081 - acc: 0.3776 - val_loss: 6.5114 - val_acc: 0.1648\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.7507 - acc: 0.3845 - val_loss: 6.5634 - val_acc: 0.1602\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.6958 - acc: 0.3923 - val_loss: 6.6096 - val_acc: 0.1668\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 53s 388us/step - loss: 2.6519 - acc: 0.3975 - val_loss: 6.6408 - val_acc: 0.1622\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 54s 390us/step - loss: 2.6055 - acc: 0.4037 - val_loss: 6.6679 - val_acc: 0.1606\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 53s 387us/step - loss: 2.5598 - acc: 0.4093 - val_loss: 6.7199 - val_acc: 0.1578\n",
      "\n",
      "loss:  2.5597767844248267 , val_loss:  6.7199353356954115\n",
      "\n",
      "SEQ_LENGTH:  1 , EMBEDDING_DIM:  152\n",
      "embedding layer is:: Tensor(\"embedding_12/embedding_lookup/Identity:0\", shape=(?, 1, 152), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15246 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 57s 416us/step - loss: 6.3700 - acc: 0.1393 - val_loss: 6.2460 - val_acc: 0.1343\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 41s 301us/step - loss: 6.1170 - acc: 0.1401 - val_loss: 6.0705 - val_acc: 0.1352\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.8716 - acc: 0.1472 - val_loss: 5.9168 - val_acc: 0.1465\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.6347 - acc: 0.1571 - val_loss: 5.8011 - val_acc: 0.1536\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 5.4083 - acc: 0.1654 - val_loss: 5.7214 - val_acc: 0.1617\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 5.1993 - acc: 0.1715 - val_loss: 5.6956 - val_acc: 0.1630\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.0203 - acc: 0.1775 - val_loss: 5.6721 - val_acc: 0.1628\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.8789 - acc: 0.1804 - val_loss: 5.6795 - val_acc: 0.1656\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.7655 - acc: 0.1853 - val_loss: 5.6826 - val_acc: 0.1657\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.6720 - acc: 0.1854 - val_loss: 5.6978 - val_acc: 0.1674\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.5963 - acc: 0.1874 - val_loss: 5.7077 - val_acc: 0.1657\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.5291 - acc: 0.1892 - val_loss: 5.7173 - val_acc: 0.1656\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.4708 - acc: 0.1891 - val_loss: 5.7267 - val_acc: 0.1712\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.4216 - acc: 0.1920 - val_loss: 5.7541 - val_acc: 0.1669\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.3778 - acc: 0.1911 - val_loss: 5.7626 - val_acc: 0.1707\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.3392 - acc: 0.1921 - val_loss: 5.7865 - val_acc: 0.1645\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.3049 - acc: 0.1920 - val_loss: 5.8114 - val_acc: 0.1662\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.2744 - acc: 0.1930 - val_loss: 5.8229 - val_acc: 0.1674\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 4.2469 - acc: 0.1929 - val_loss: 5.8447 - val_acc: 0.1670\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 41s 299us/step - loss: 4.2219 - acc: 0.1930 - val_loss: 5.8679 - val_acc: 0.1670\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.1993 - acc: 0.1931 - val_loss: 5.8842 - val_acc: 0.1634\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.1788 - acc: 0.1940 - val_loss: 5.8955 - val_acc: 0.1678\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.1594 - acc: 0.1937 - val_loss: 5.9202 - val_acc: 0.1684\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1418 - acc: 0.1942 - val_loss: 5.9318 - val_acc: 0.1709\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1269 - acc: 0.1944 - val_loss: 5.9445 - val_acc: 0.1666\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1137 - acc: 0.1937 - val_loss: 5.9589 - val_acc: 0.1694\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0997 - acc: 0.1932 - val_loss: 5.9778 - val_acc: 0.1640\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0856 - acc: 0.1940 - val_loss: 5.9892 - val_acc: 0.1684\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0772 - acc: 0.1944 - val_loss: 5.9955 - val_acc: 0.1662\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0653 - acc: 0.1944 - val_loss: 6.0135 - val_acc: 0.1643\n",
      "\n",
      "loss:  4.065287337319322 , val_loss:  6.013496304721825\n",
      "\n",
      "SEQ_LENGTH:  1 , EMBEDDING_DIM:  152\n",
      "embedding layer is:: Tensor(\"embedding_13/embedding_lookup/Identity:0\", shape=(?, 1, 152), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15246 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 58s 419us/step - loss: 6.3733 - acc: 0.1393 - val_loss: 6.2439 - val_acc: 0.1341\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 6.1225 - acc: 0.1398 - val_loss: 6.0829 - val_acc: 0.1351\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 5.8961 - acc: 0.1457 - val_loss: 5.9237 - val_acc: 0.1452\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 5.6651 - acc: 0.1556 - val_loss: 5.8228 - val_acc: 0.1512\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.4451 - acc: 0.1636 - val_loss: 5.7380 - val_acc: 0.1596\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.2245 - acc: 0.1717 - val_loss: 5.6951 - val_acc: 0.1626\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 5.0411 - acc: 0.1771 - val_loss: 5.6603 - val_acc: 0.1631\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.8947 - acc: 0.1809 - val_loss: 5.6493 - val_acc: 0.1671\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.7774 - acc: 0.1833 - val_loss: 5.6593 - val_acc: 0.1641\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.6812 - acc: 0.1862 - val_loss: 5.6652 - val_acc: 0.1668\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 4.5986 - acc: 0.1885 - val_loss: 5.6779 - val_acc: 0.1695\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.5331 - acc: 0.1880 - val_loss: 5.6781 - val_acc: 0.1730\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.4761 - acc: 0.1892 - val_loss: 5.7063 - val_acc: 0.1687\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.4264 - acc: 0.1905 - val_loss: 5.7239 - val_acc: 0.1659\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.3812 - acc: 0.1916 - val_loss: 5.7464 - val_acc: 0.1674\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.3430 - acc: 0.1909 - val_loss: 5.7675 - val_acc: 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 4.3095 - acc: 0.1915 - val_loss: 5.7832 - val_acc: 0.1700\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 4.2795 - acc: 0.1910 - val_loss: 5.7942 - val_acc: 0.1697\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 42s 308us/step - loss: 4.2531 - acc: 0.1930 - val_loss: 5.8253 - val_acc: 0.1642\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.2257 - acc: 0.1931 - val_loss: 5.8357 - val_acc: 0.1713\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.2050 - acc: 0.1936 - val_loss: 5.8626 - val_acc: 0.1665\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1840 - acc: 0.1923 - val_loss: 5.8747 - val_acc: 0.1678\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1663 - acc: 0.1934 - val_loss: 5.8933 - val_acc: 0.1648\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 4.1484 - acc: 0.1931 - val_loss: 5.9023 - val_acc: 0.1670\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1339 - acc: 0.1930 - val_loss: 5.9235 - val_acc: 0.1648\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1195 - acc: 0.1935 - val_loss: 5.9328 - val_acc: 0.1685\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1069 - acc: 0.1941 - val_loss: 5.9484 - val_acc: 0.1659\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0945 - acc: 0.1942 - val_loss: 5.9696 - val_acc: 0.1686\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0810 - acc: 0.1945 - val_loss: 5.9792 - val_acc: 0.1669\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0724 - acc: 0.1948 - val_loss: 5.9848 - val_acc: 0.1684\n",
      "\n",
      "loss:  4.072361211747888 , val_loss:  5.984848031468487\n",
      "\n",
      "SEQ_LENGTH:  1 , EMBEDDING_DIM:  152\n",
      "embedding layer is:: Tensor(\"embedding_14/embedding_lookup/Identity:0\", shape=(?, 1, 152), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15246 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 60s 434us/step - loss: 6.3701 - acc: 0.1393 - val_loss: 6.2335 - val_acc: 0.1366\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 6.1041 - acc: 0.1400 - val_loss: 6.0646 - val_acc: 0.1375\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 5.8664 - acc: 0.1482 - val_loss: 5.8905 - val_acc: 0.1473\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.6388 - acc: 0.1571 - val_loss: 5.7994 - val_acc: 0.1572\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 5.4263 - acc: 0.1643 - val_loss: 5.7428 - val_acc: 0.1590\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.2166 - acc: 0.1705 - val_loss: 5.6831 - val_acc: 0.1657\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 5.0367 - acc: 0.1765 - val_loss: 5.6641 - val_acc: 0.1648\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.8932 - acc: 0.1808 - val_loss: 5.6648 - val_acc: 0.1667\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.7802 - acc: 0.1834 - val_loss: 5.6608 - val_acc: 0.1703\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.6865 - acc: 0.1851 - val_loss: 5.6667 - val_acc: 0.1679\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.6087 - acc: 0.1865 - val_loss: 5.6738 - val_acc: 0.1673\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.5430 - acc: 0.1889 - val_loss: 5.6915 - val_acc: 0.1707\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.4847 - acc: 0.1895 - val_loss: 5.7074 - val_acc: 0.1694\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 43s 315us/step - loss: 4.4367 - acc: 0.1901 - val_loss: 5.7222 - val_acc: 0.1646\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 41s 299us/step - loss: 4.3918 - acc: 0.1913 - val_loss: 5.7385 - val_acc: 0.1723\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.3538 - acc: 0.1915 - val_loss: 5.7547 - val_acc: 0.1675\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.3190 - acc: 0.1921 - val_loss: 5.7851 - val_acc: 0.1690\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.2878 - acc: 0.1926 - val_loss: 5.7924 - val_acc: 0.1662\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.2604 - acc: 0.1924 - val_loss: 5.8108 - val_acc: 0.1692\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 4.2366 - acc: 0.1925 - val_loss: 5.8264 - val_acc: 0.1704\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.2114 - acc: 0.1941 - val_loss: 5.8421 - val_acc: 0.1679\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1919 - acc: 0.1932 - val_loss: 5.8641 - val_acc: 0.1678\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 41s 299us/step - loss: 4.1732 - acc: 0.1933 - val_loss: 5.8791 - val_acc: 0.1679\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 4.1541 - acc: 0.1935 - val_loss: 5.8936 - val_acc: 0.1704\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 41s 298us/step - loss: 4.1377 - acc: 0.1939 - val_loss: 5.9127 - val_acc: 0.1662\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1245 - acc: 0.1938 - val_loss: 5.9200 - val_acc: 0.1705\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.1111 - acc: 0.1934 - val_loss: 5.9427 - val_acc: 0.1631\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0996 - acc: 0.1938 - val_loss: 5.9512 - val_acc: 0.1657\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0864 - acc: 0.1940 - val_loss: 5.9609 - val_acc: 0.1668\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 4.0762 - acc: 0.1949 - val_loss: 5.9804 - val_acc: 0.1674\n",
      "\n",
      "loss:  4.076203750683891 , val_loss:  5.980354868425842\n",
      "\n",
      "SEQ_LENGTH:  1 , EMBEDDING_DIM:  152\n",
      "embedding layer is:: Tensor(\"embedding_15/embedding_lookup/Identity:0\", shape=(?, 1, 152), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15246 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 61s 448us/step - loss: 6.3713 - acc: 0.1393 - val_loss: 6.2421 - val_acc: 0.1361\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 6.1057 - acc: 0.1404 - val_loss: 6.0745 - val_acc: 0.1372\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 42s 303us/step - loss: 5.8652 - acc: 0.1472 - val_loss: 5.8992 - val_acc: 0.1485\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 5.6305 - acc: 0.1565 - val_loss: 5.8037 - val_acc: 0.1562\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 41s 301us/step - loss: 5.4193 - acc: 0.1652 - val_loss: 5.7365 - val_acc: 0.1628\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 5.2172 - acc: 0.1723 - val_loss: 5.7027 - val_acc: 0.1623\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 5.0437 - acc: 0.1767 - val_loss: 5.6709 - val_acc: 0.1682\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.9051 - acc: 0.1799 - val_loss: 5.6654 - val_acc: 0.1625\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 42s 303us/step - loss: 4.7905 - acc: 0.1827 - val_loss: 5.6648 - val_acc: 0.1664\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 42s 303us/step - loss: 4.6993 - acc: 0.1852 - val_loss: 5.6792 - val_acc: 0.1687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 41s 301us/step - loss: 4.6225 - acc: 0.1861 - val_loss: 5.6896 - val_acc: 0.1667\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 41s 301us/step - loss: 4.5573 - acc: 0.1876 - val_loss: 5.7086 - val_acc: 0.1658\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 42s 303us/step - loss: 4.4998 - acc: 0.1893 - val_loss: 5.7229 - val_acc: 0.1669\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.4511 - acc: 0.1895 - val_loss: 5.7393 - val_acc: 0.1682\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 42s 304us/step - loss: 4.4062 - acc: 0.1891 - val_loss: 5.7495 - val_acc: 0.1711\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.3682 - acc: 0.1904 - val_loss: 5.7727 - val_acc: 0.1673\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.3335 - acc: 0.1906 - val_loss: 5.7995 - val_acc: 0.1661\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 42s 303us/step - loss: 4.3015 - acc: 0.1907 - val_loss: 5.8160 - val_acc: 0.1657\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.2725 - acc: 0.1919 - val_loss: 5.8254 - val_acc: 0.1705\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.2473 - acc: 0.1926 - val_loss: 5.8528 - val_acc: 0.1663\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.2238 - acc: 0.1922 - val_loss: 5.8585 - val_acc: 0.1679\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 41s 302us/step - loss: 4.2046 - acc: 0.1922 - val_loss: 5.8864 - val_acc: 0.1671\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 42s 302us/step - loss: 4.1848 - acc: 0.1936 - val_loss: 5.9025 - val_acc: 0.1688\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 42s 303us/step - loss: 4.1661 - acc: 0.1930 - val_loss: 5.9212 - val_acc: 0.1638\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 42s 303us/step - loss: 4.1502 - acc: 0.1929 - val_loss: 5.9359 - val_acc: 0.1663\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 42s 304us/step - loss: 4.1352 - acc: 0.1932 - val_loss: 5.9491 - val_acc: 0.1694\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 41s 301us/step - loss: 4.1205 - acc: 0.1936 - val_loss: 5.9676 - val_acc: 0.1688\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 4.1078 - acc: 0.1936 - val_loss: 5.9755 - val_acc: 0.1692\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 4.0953 - acc: 0.1946 - val_loss: 5.9879 - val_acc: 0.1659\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 41s 300us/step - loss: 4.0862 - acc: 0.1937 - val_loss: 6.0079 - val_acc: 0.1685\n",
      "\n",
      "loss:  4.086204052385003 , val_loss:  6.007884079181161\n",
      "\n",
      "SEQ_LENGTH:  1 , EMBEDDING_DIM:  152\n",
      "embedding layer is:: Tensor(\"embedding_16/embedding_lookup/Identity:0\", shape=(?, 1, 152), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15246 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 60s 439us/step - loss: 6.3667 - acc: 0.1392 - val_loss: 6.2327 - val_acc: 0.1351\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 40s 295us/step - loss: 6.1096 - acc: 0.1400 - val_loss: 6.0803 - val_acc: 0.1373\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.8802 - acc: 0.1457 - val_loss: 5.9245 - val_acc: 0.1473\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.6412 - acc: 0.1564 - val_loss: 5.8167 - val_acc: 0.1546\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 5.4214 - acc: 0.1646 - val_loss: 5.7460 - val_acc: 0.1574\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 41s 297us/step - loss: 5.2203 - acc: 0.1711 - val_loss: 5.7055 - val_acc: 0.1629\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 5.0462 - acc: 0.1769 - val_loss: 5.6772 - val_acc: 0.1672\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.9045 - acc: 0.1809 - val_loss: 5.6770 - val_acc: 0.1661\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.7899 - acc: 0.1836 - val_loss: 5.6647 - val_acc: 0.1684\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.6954 - acc: 0.1858 - val_loss: 5.6746 - val_acc: 0.1661\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.6189 - acc: 0.1881 - val_loss: 5.6906 - val_acc: 0.1669\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.5488 - acc: 0.1878 - val_loss: 5.6943 - val_acc: 0.1715\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.4928 - acc: 0.1897 - val_loss: 5.7166 - val_acc: 0.1725\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.4421 - acc: 0.1901 - val_loss: 5.7314 - val_acc: 0.1671\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 40s 292us/step - loss: 4.3969 - acc: 0.1916 - val_loss: 5.7512 - val_acc: 0.1685\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.3591 - acc: 0.1919 - val_loss: 5.7728 - val_acc: 0.1693\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.3240 - acc: 0.1912 - val_loss: 5.7914 - val_acc: 0.1661\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.2929 - acc: 0.1930 - val_loss: 5.8111 - val_acc: 0.1678\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.2661 - acc: 0.1922 - val_loss: 5.8185 - val_acc: 0.1677\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.2412 - acc: 0.1925 - val_loss: 5.8306 - val_acc: 0.1695\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.2194 - acc: 0.1932 - val_loss: 5.8570 - val_acc: 0.1665\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 40s 292us/step - loss: 4.2002 - acc: 0.1936 - val_loss: 5.8672 - val_acc: 0.1678\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.1803 - acc: 0.1932 - val_loss: 5.8862 - val_acc: 0.1672\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.1612 - acc: 0.1935 - val_loss: 5.9000 - val_acc: 0.1673\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1452 - acc: 0.1943 - val_loss: 5.9216 - val_acc: 0.1680\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.1329 - acc: 0.1940 - val_loss: 5.9322 - val_acc: 0.1677\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 40s 293us/step - loss: 4.1177 - acc: 0.1942 - val_loss: 5.9539 - val_acc: 0.1689\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 41s 296us/step - loss: 4.1080 - acc: 0.1937 - val_loss: 5.9616 - val_acc: 0.1677\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 40s 295us/step - loss: 4.0941 - acc: 0.1932 - val_loss: 5.9783 - val_acc: 0.1684\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 40s 294us/step - loss: 4.0827 - acc: 0.1945 - val_loss: 5.9950 - val_acc: 0.1683\n",
      "\n",
      "loss:  4.082714736792234 , val_loss:  5.99499081570724\n",
      "\n",
      "SEQ_LENGTH:  6 , EMBEDDING_DIM:  105\n",
      "embedding layer is:: Tensor(\"embedding_17/embedding_lookup/Identity:0\", shape=(?, 6, 105), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137201 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137201/137201 [==============================] - 160s 1ms/step - loss: 6.2961 - acc: 0.1410 - val_loss: 6.1617 - val_acc: 0.1398\n",
      "Epoch 2/30\n",
      "137201/137201 [==============================] - 146s 1ms/step - loss: 5.9716 - acc: 0.1457 - val_loss: 5.9332 - val_acc: 0.1485\n",
      "Epoch 3/30\n",
      "137201/137201 [==============================] - 142s 1ms/step - loss: 5.6303 - acc: 0.1602 - val_loss: 5.7764 - val_acc: 0.1618\n",
      "Epoch 4/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 5.3141 - acc: 0.1762 - val_loss: 5.7089 - val_acc: 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 5.0243 - acc: 0.1907 - val_loss: 5.6735 - val_acc: 0.1762\n",
      "Epoch 6/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 4.7590 - acc: 0.2072 - val_loss: 5.6860 - val_acc: 0.1764\n",
      "Epoch 7/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 4.5074 - acc: 0.2258 - val_loss: 5.7301 - val_acc: 0.1774\n",
      "Epoch 8/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 4.2613 - acc: 0.2497 - val_loss: 5.7818 - val_acc: 0.1750\n",
      "Epoch 9/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 4.0265 - acc: 0.2752 - val_loss: 5.8341 - val_acc: 0.1809\n",
      "Epoch 10/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 3.7976 - acc: 0.3061 - val_loss: 5.8880 - val_acc: 0.1783\n",
      "Epoch 11/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 3.5772 - acc: 0.3369 - val_loss: 5.9544 - val_acc: 0.1757\n",
      "Epoch 12/30\n",
      "137201/137201 [==============================] - 143s 1ms/step - loss: 3.3696 - acc: 0.3684 - val_loss: 6.0178 - val_acc: 0.1756\n",
      "Epoch 13/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 3.1748 - acc: 0.4018 - val_loss: 6.0808 - val_acc: 0.1736\n",
      "Epoch 14/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 2.9949 - acc: 0.4295 - val_loss: 6.1703 - val_acc: 0.1729\n",
      "Epoch 15/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 2.8201 - acc: 0.4622 - val_loss: 6.2368 - val_acc: 0.1706\n",
      "Epoch 16/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 2.6591 - acc: 0.4884 - val_loss: 6.3135 - val_acc: 0.1753\n",
      "Epoch 17/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 2.5113 - acc: 0.5144 - val_loss: 6.3915 - val_acc: 0.1701\n",
      "Epoch 18/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 2.3745 - acc: 0.5386 - val_loss: 6.4631 - val_acc: 0.1704\n",
      "Epoch 19/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 2.2414 - acc: 0.5617 - val_loss: 6.5455 - val_acc: 0.1724\n",
      "Epoch 20/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 2.1199 - acc: 0.5831 - val_loss: 6.6149 - val_acc: 0.1704\n",
      "Epoch 21/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 2.0066 - acc: 0.6049 - val_loss: 6.6939 - val_acc: 0.1705\n",
      "Epoch 22/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 1.9019 - acc: 0.6237 - val_loss: 6.7694 - val_acc: 0.1675\n",
      "Epoch 23/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 1.8081 - acc: 0.6407 - val_loss: 6.8665 - val_acc: 0.1726\n",
      "Epoch 24/30\n",
      "137201/137201 [==============================] - 141s 1ms/step - loss: 1.7137 - acc: 0.6581 - val_loss: 6.9061 - val_acc: 0.1729\n",
      "Epoch 25/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 1.6295 - acc: 0.6735 - val_loss: 7.0049 - val_acc: 0.1692\n",
      "Epoch 26/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 1.5497 - acc: 0.6871 - val_loss: 7.0869 - val_acc: 0.1752\n",
      "Epoch 27/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 1.4747 - acc: 0.7020 - val_loss: 7.1888 - val_acc: 0.1729\n",
      "Epoch 28/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 1.4082 - acc: 0.7148 - val_loss: 7.2116 - val_acc: 0.1743\n",
      "Epoch 29/30\n",
      "137201/137201 [==============================] - 140s 1ms/step - loss: 1.3430 - acc: 0.7259 - val_loss: 7.2846 - val_acc: 0.1690\n",
      "Epoch 30/30\n",
      "137201/137201 [==============================] - 143s 1ms/step - loss: 1.2840 - acc: 0.7368 - val_loss: 7.3748 - val_acc: 0.1693\n",
      "\n",
      "loss:  1.283999028878791 , val_loss:  7.374849812137607\n",
      "\n",
      "SEQ_LENGTH:  5 , EMBEDDING_DIM:  169\n",
      "embedding layer is:: Tensor(\"embedding_18/embedding_lookup/Identity:0\", shape=(?, 5, 169), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137202 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137202/137202 [==============================] - 146s 1ms/step - loss: 6.2959 - acc: 0.1410 - val_loss: 6.1515 - val_acc: 0.1398\n",
      "Epoch 2/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 5.9180 - acc: 0.1470 - val_loss: 5.8927 - val_acc: 0.1473\n",
      "Epoch 3/30\n",
      "137202/137202 [==============================] - 122s 893us/step - loss: 5.5287 - acc: 0.1650 - val_loss: 5.7306 - val_acc: 0.1655\n",
      "Epoch 4/30\n",
      "137202/137202 [==============================] - 123s 894us/step - loss: 5.1709 - acc: 0.1863 - val_loss: 5.6518 - val_acc: 0.1761\n",
      "Epoch 5/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 4.8500 - acc: 0.2062 - val_loss: 5.6534 - val_acc: 0.1812\n",
      "Epoch 6/30\n",
      "137202/137202 [==============================] - 122s 890us/step - loss: 4.5495 - acc: 0.2282 - val_loss: 5.7023 - val_acc: 0.1754\n",
      "Epoch 7/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 4.2561 - acc: 0.2559 - val_loss: 5.7426 - val_acc: 0.1789\n",
      "Epoch 8/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 3.9763 - acc: 0.2864 - val_loss: 5.7958 - val_acc: 0.1753\n",
      "Epoch 9/30\n",
      "137202/137202 [==============================] - 122s 890us/step - loss: 3.7086 - acc: 0.3222 - val_loss: 5.8521 - val_acc: 0.1755\n",
      "Epoch 10/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 3.4530 - acc: 0.3594 - val_loss: 5.9288 - val_acc: 0.1782\n",
      "Epoch 11/30\n",
      "137202/137202 [==============================] - 123s 894us/step - loss: 3.2175 - acc: 0.3960 - val_loss: 6.0086 - val_acc: 0.1767\n",
      "Epoch 12/30\n",
      "137202/137202 [==============================] - 122s 892us/step - loss: 2.9950 - acc: 0.4323 - val_loss: 6.0842 - val_acc: 0.1702\n",
      "Epoch 13/30\n",
      "137202/137202 [==============================] - 124s 906us/step - loss: 2.7919 - acc: 0.4668 - val_loss: 6.1771 - val_acc: 0.1719\n",
      "Epoch 14/30\n",
      "137202/137202 [==============================] - 123s 896us/step - loss: 2.5970 - acc: 0.5006 - val_loss: 6.2664 - val_acc: 0.1654\n",
      "Epoch 15/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 2.4239 - acc: 0.5301 - val_loss: 6.3583 - val_acc: 0.1658\n",
      "Epoch 16/30\n",
      "137202/137202 [==============================] - 122s 890us/step - loss: 2.2612 - acc: 0.5598 - val_loss: 6.4547 - val_acc: 0.1673\n",
      "Epoch 17/30\n",
      "137202/137202 [==============================] - 124s 904us/step - loss: 2.1085 - acc: 0.5869 - val_loss: 6.5339 - val_acc: 0.1702\n",
      "Epoch 18/30\n",
      "137202/137202 [==============================] - 123s 895us/step - loss: 1.9729 - acc: 0.6116 - val_loss: 6.6269 - val_acc: 0.1676\n",
      "Epoch 19/30\n",
      "137202/137202 [==============================] - 122s 890us/step - loss: 1.8458 - acc: 0.6330 - val_loss: 6.7329 - val_acc: 0.1639\n",
      "Epoch 20/30\n",
      "137202/137202 [==============================] - 123s 898us/step - loss: 1.7272 - acc: 0.6553 - val_loss: 6.8146 - val_acc: 0.1651\n",
      "Epoch 21/30\n",
      "137202/137202 [==============================] - 124s 901us/step - loss: 1.6147 - acc: 0.6768 - val_loss: 6.9116 - val_acc: 0.1690\n",
      "Epoch 22/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 1.5137 - acc: 0.6960 - val_loss: 6.9846 - val_acc: 0.1697\n",
      "Epoch 23/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 1.4233 - acc: 0.7119 - val_loss: 7.0853 - val_acc: 0.1684\n",
      "Epoch 24/30\n",
      "137202/137202 [==============================] - 122s 890us/step - loss: 1.3444 - acc: 0.7249 - val_loss: 7.1591 - val_acc: 0.1690\n",
      "Epoch 25/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 1.2594 - acc: 0.7419 - val_loss: 7.2479 - val_acc: 0.1704\n",
      "Epoch 26/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 1.1846 - acc: 0.7563 - val_loss: 7.3157 - val_acc: 0.1646\n",
      "Epoch 27/30\n",
      "137202/137202 [==============================] - 122s 892us/step - loss: 1.1201 - acc: 0.7691 - val_loss: 7.4252 - val_acc: 0.1679\n",
      "Epoch 28/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 1.0571 - acc: 0.7808 - val_loss: 7.4835 - val_acc: 0.1689\n",
      "Epoch 29/30\n",
      "137202/137202 [==============================] - 122s 889us/step - loss: 0.9954 - acc: 0.7915 - val_loss: 7.5802 - val_acc: 0.1663\n",
      "Epoch 30/30\n",
      "137202/137202 [==============================] - 122s 891us/step - loss: 0.9446 - acc: 0.8010 - val_loss: 7.6297 - val_acc: 0.1674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss:  0.9445690258341929 , val_loss:  7.6297400824043855\n",
      "\n",
      "SEQ_LENGTH:  2 , EMBEDDING_DIM:  88\n",
      "embedding layer is:: Tensor(\"embedding_19/embedding_lookup/Identity:0\", shape=(?, 2, 88), dtype=float32)\n",
      "build model.....\n",
      "Train....\n",
      "Train on 137205 samples, validate on 15245 samples\n",
      "Epoch 1/30\n",
      "137205/137205 [==============================] - 89s 646us/step - loss: 6.3437 - acc: 0.1395 - val_loss: 6.2060 - val_acc: 0.1376\n",
      "Epoch 2/30\n",
      "137205/137205 [==============================] - 61s 448us/step - loss: 5.9932 - acc: 0.1454 - val_loss: 5.9600 - val_acc: 0.1473\n",
      "Epoch 3/30\n",
      "137205/137205 [==============================] - 61s 442us/step - loss: 5.6563 - acc: 0.1604 - val_loss: 5.7734 - val_acc: 0.1592\n",
      "Epoch 4/30\n",
      "137205/137205 [==============================] - 61s 442us/step - loss: 5.3580 - acc: 0.1761 - val_loss: 5.7324 - val_acc: 0.1660\n",
      "Epoch 5/30\n",
      "137205/137205 [==============================] - 61s 442us/step - loss: 5.0718 - acc: 0.1894 - val_loss: 5.6831 - val_acc: 0.1728\n",
      "Epoch 6/30\n",
      "137205/137205 [==============================] - 61s 442us/step - loss: 4.8015 - acc: 0.2032 - val_loss: 5.6953 - val_acc: 0.1788\n",
      "Epoch 7/30\n",
      "137205/137205 [==============================] - 61s 442us/step - loss: 4.5522 - acc: 0.2175 - val_loss: 5.7222 - val_acc: 0.1786\n",
      "Epoch 8/30\n",
      "137205/137205 [==============================] - 61s 446us/step - loss: 4.3298 - acc: 0.2327 - val_loss: 5.7572 - val_acc: 0.1801\n",
      "Epoch 9/30\n",
      "137205/137205 [==============================] - 61s 442us/step - loss: 4.1211 - acc: 0.2484 - val_loss: 5.8018 - val_acc: 0.1759\n",
      "Epoch 10/30\n",
      "137205/137205 [==============================] - 60s 439us/step - loss: 3.9364 - acc: 0.2628 - val_loss: 5.8417 - val_acc: 0.1770\n",
      "Epoch 11/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 3.7644 - acc: 0.2789 - val_loss: 5.8952 - val_acc: 0.1799\n",
      "Epoch 12/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 3.6103 - acc: 0.2934 - val_loss: 5.9490 - val_acc: 0.1766\n",
      "Epoch 13/30\n",
      "137205/137205 [==============================] - 60s 439us/step - loss: 3.4650 - acc: 0.3104 - val_loss: 6.0098 - val_acc: 0.1772\n",
      "Epoch 14/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 3.3381 - acc: 0.3228 - val_loss: 6.0685 - val_acc: 0.1743\n",
      "Epoch 15/30\n",
      "137205/137205 [==============================] - 60s 439us/step - loss: 3.2133 - acc: 0.3363 - val_loss: 6.1447 - val_acc: 0.1709\n",
      "Epoch 16/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 3.1025 - acc: 0.3504 - val_loss: 6.1874 - val_acc: 0.1742\n",
      "Epoch 17/30\n",
      "137205/137205 [==============================] - 60s 439us/step - loss: 3.0011 - acc: 0.3621 - val_loss: 6.2557 - val_acc: 0.1683\n",
      "Epoch 18/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.9065 - acc: 0.3741 - val_loss: 6.3169 - val_acc: 0.1713\n",
      "Epoch 19/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.8206 - acc: 0.3828 - val_loss: 6.3737 - val_acc: 0.1675\n",
      "Epoch 20/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.7438 - acc: 0.3929 - val_loss: 6.4275 - val_acc: 0.1696\n",
      "Epoch 21/30\n",
      "137205/137205 [==============================] - 60s 441us/step - loss: 2.6700 - acc: 0.4016 - val_loss: 6.4861 - val_acc: 0.1681\n",
      "Epoch 22/30\n",
      "137205/137205 [==============================] - 61s 441us/step - loss: 2.6019 - acc: 0.4122 - val_loss: 6.5462 - val_acc: 0.1636\n",
      "Epoch 23/30\n",
      "137205/137205 [==============================] - 61s 443us/step - loss: 2.5412 - acc: 0.4192 - val_loss: 6.6028 - val_acc: 0.1633\n",
      "Epoch 24/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.4846 - acc: 0.4253 - val_loss: 6.6550 - val_acc: 0.1629\n",
      "Epoch 25/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.4293 - acc: 0.4335 - val_loss: 6.7025 - val_acc: 0.1587\n",
      "Epoch 26/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.3865 - acc: 0.4365 - val_loss: 6.7601 - val_acc: 0.1648\n",
      "Epoch 27/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.3437 - acc: 0.4429 - val_loss: 6.8050 - val_acc: 0.1612\n",
      "Epoch 28/30\n",
      "137205/137205 [==============================] - 60s 440us/step - loss: 2.3009 - acc: 0.4489 - val_loss: 6.8442 - val_acc: 0.1606\n",
      "Epoch 29/30\n",
      "137205/137205 [==============================] - 60s 439us/step - loss: 2.2604 - acc: 0.4538 - val_loss: 6.9028 - val_acc: 0.1601\n",
      "Epoch 30/30\n",
      "137205/137205 [==============================] - 60s 439us/step - loss: 2.2274 - acc: 0.4576 - val_loss: 6.9402 - val_acc: 0.1637\n",
      "\n",
      "loss:  2.2274053323799317 , val_loss:  6.940214381385295\n"
     ]
    }
   ],
   "source": [
    "population_size = 6\n",
    "num_generations = 6\n",
    "gene_length = 11\n",
    "\n",
    "# As we are trying to minimize the Loss and the Validation_loss, that's why using -1.0. \n",
    "# In case, when you want to maximize accuracy for instance, use 1.0\n",
    "creator.create('FitnessMulti', base.Fitness, weights = (-1.0, -1.0))\n",
    "creator.create('Individual', list , fitness = creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', model_lstm)\n",
    "\n",
    "population = toolbox.population(n = population_size)\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.2, ngen = num_generations, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEQ_LENGTH:  4 , EMBEDDING_DIM:  168\n"
     ]
    }
   ],
   "source": [
    "best_individuals = tools.selBest(population,k = 1)\n",
    "\n",
    "SEQ_LENGTH = None\n",
    "EMBEDDING_DIM = None\n",
    "\n",
    "for bi in best_individuals:\n",
    "    SEQ_LENGTH_bits = BitArray(bi[0:3])\n",
    "    SEQ_LENGTH = SEQ_LENGTH_bits.uint\n",
    "\n",
    "    EMBEDDING_DIM_bits = BitArray(bi[3:]) \n",
    "    EMBEDDING_DIM = EMBEDDING_DIM_bits.uint\n",
    "    \n",
    "    print('\\nSEQ_LENGTH: ', SEQ_LENGTH, ', EMBEDDING_DIM: ', EMBEDDING_DIM)#, ', Hidden_size_1: ', Hidden_size_1, ', Hidden_size_2 ', Hidden_size_2)#, ', Hidden_size_3', Hidden_size_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadParam(model_file, word2index_file, index2word_file):\n",
    "    \"\"\"\n",
    "    load model and word2index_file, index2word_file\n",
    "    :param model_file:\n",
    "    :param word2index_file:\n",
    "    :param index2word_file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # get model.\n",
    "    model = load_model(model_file)\n",
    "    # get the word2index and index2word data.\n",
    "    with open(word2index_file, 'r', encoding='utf8') as f:\n",
    "        json_obj = f.read()\n",
    "        word2index = json.loads(json_obj)\n",
    "        f.close()\n",
    "    with open(index2word_file, 'r', encoding='utf8') as f:\n",
    "        json_obj = f.read()\n",
    "        index2word = json.loads(json_obj)\n",
    "        f.close()\n",
    "    index2word_new = {}\n",
    "    for key, value in index2word.items():\n",
    "        index2word_new[int(key)] = value\n",
    "    return model, word2index, index2word_new\n",
    "\n",
    "def sample(preds, diversity = 1.0):\n",
    "    \"\"\"\n",
    "    get the max probability index.\n",
    "    :param preds: prediction\n",
    "    :param diversity:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds + 1e-10) / diversity\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def lyrics_generate(start, model, word2index, index2word, SEQ_LENGTH, generate_maxlen):\n",
    "    \"\"\"\n",
    "    generate lyrics according start sentence.\n",
    "    :param start: startWith sentence\n",
    "    :param model:\n",
    "    :param word2index:\n",
    "    :param index2word:\n",
    "    :param maxlen: the length of generating sentence.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sentence = start[:SEQ_LENGTH]   \n",
    "    diversity = 1.0\n",
    "    while len(sentence) < generate_maxlen:\n",
    "        \n",
    "        x_pred = np.zeros((1, SEQ_LENGTH))    \n",
    "\n",
    "        min_index = max(0, len(sentence) - SEQ_LENGTH)    \n",
    "        for idx in range(min_index, len(sentence)):\n",
    "            x_pred[0, SEQ_LENGTH - len(sentence) + idx] = word2index.get(sentence[idx], 1)  \n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]   \n",
    "        next_index = sample(preds, diversity)   \n",
    "        next_word = index2word[next_index]\n",
    "        if not (next_word == '。' and sentence[-1] == '。'):   \n",
    "            sentence = sentence + next_word  \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEQ_LENGTH:  5 , EMBEDDING_DIM:  169 , Hidden_size_1:  512 , Hidden_size_2  512 , Hidden_size_3 256\n",
      "embedding layer is:: Tensor(\"embedding_3/embedding_lookup/Identity:0\", shape=(?, 5, 169), dtype=float32)\n",
      "build model.....\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x_train (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 5, 169)            576628    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 5, 1024)           2793472   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 5, 1024)           6295552   \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 512)               2623488   \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 3412)              1750356   \n",
      "=================================================================\n",
      "Total params: 14,039,496\n",
      "Trainable params: 14,039,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train....\n",
      "Train on 137202 samples, validate on 15245 samples\n",
      "Epoch 1/50\n",
      "137202/137202 [==============================] - 80s 580us/step - loss: 6.3713 - acc: 0.1396 - val_loss: 6.2145 - val_acc: 0.1398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.21455, saving model to ./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5\n",
      "Epoch 2/50\n",
      "137202/137202 [==============================] - 72s 527us/step - loss: 6.0958 - acc: 0.1425 - val_loss: 6.0952 - val_acc: 0.1405\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.21455 to 6.09515, saving model to ./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5\n",
      "Epoch 3/50\n",
      "137202/137202 [==============================] - 72s 528us/step - loss: 5.8417 - acc: 0.1479 - val_loss: 5.8998 - val_acc: 0.1500\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.09515 to 5.89981, saving model to ./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5\n",
      "Epoch 4/50\n",
      "137202/137202 [==============================] - 72s 527us/step - loss: 5.5651 - acc: 0.1625 - val_loss: 5.7817 - val_acc: 0.1601\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.89981 to 5.78174, saving model to ./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5\n",
      "Epoch 5/50\n",
      "137202/137202 [==============================] - 72s 527us/step - loss: 5.3025 - acc: 0.1774 - val_loss: 5.7212 - val_acc: 0.1698\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.78174 to 5.72124, saving model to ./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5\n",
      "Epoch 6/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 5.0608 - acc: 0.1926 - val_loss: 5.6729 - val_acc: 0.1726\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.72124 to 5.67287, saving model to ./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5\n",
      "Epoch 7/50\n",
      "137202/137202 [==============================] - 74s 542us/step - loss: 4.8355 - acc: 0.2047 - val_loss: 5.6828 - val_acc: 0.1729\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.67287\n",
      "Epoch 8/50\n",
      "137202/137202 [==============================] - 73s 532us/step - loss: 4.6277 - acc: 0.2200 - val_loss: 5.6778 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5.67287\n",
      "Epoch 9/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 4.4234 - acc: 0.2363 - val_loss: 5.7067 - val_acc: 0.1780\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 5.67287\n",
      "Epoch 10/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 4.2263 - acc: 0.2544 - val_loss: 5.7366 - val_acc: 0.1775\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5.67287\n",
      "Epoch 11/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 4.0293 - acc: 0.2747 - val_loss: 5.7672 - val_acc: 0.1767\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 5.67287\n",
      "Epoch 12/50\n",
      "137202/137202 [==============================] - 73s 530us/step - loss: 3.7263 - acc: 0.3118 - val_loss: 5.7689 - val_acc: 0.1801\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 5.67287\n",
      "Epoch 13/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.6532 - acc: 0.3245 - val_loss: 5.7760 - val_acc: 0.1796\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 5.67287\n",
      "Epoch 14/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.6077 - acc: 0.3322 - val_loss: 5.7817 - val_acc: 0.1780\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 5.67287\n",
      "Epoch 15/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.5761 - acc: 0.3364 - val_loss: 5.7885 - val_acc: 0.1783\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 5.67287\n",
      "Epoch 16/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.5461 - acc: 0.3414 - val_loss: 5.7958 - val_acc: 0.1782\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 5.67287\n",
      "Epoch 17/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.5074 - acc: 0.3479 - val_loss: 5.7962 - val_acc: 0.1790\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 5.67287\n",
      "Epoch 18/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.5036 - acc: 0.3476 - val_loss: 5.7975 - val_acc: 0.1794\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 5.67287\n",
      "Epoch 19/50\n",
      "137202/137202 [==============================] - 73s 532us/step - loss: 3.4994 - acc: 0.3495 - val_loss: 5.7981 - val_acc: 0.1789\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5.67287\n",
      "Epoch 20/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4976 - acc: 0.3493 - val_loss: 5.7986 - val_acc: 0.1792\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.67287\n",
      "Epoch 21/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4943 - acc: 0.3486 - val_loss: 5.7997 - val_acc: 0.1791\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.67287\n",
      "Epoch 22/50\n",
      "137202/137202 [==============================] - 72s 528us/step - loss: 3.4910 - acc: 0.3500 - val_loss: 5.7999 - val_acc: 0.1792\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.67287\n",
      "Epoch 23/50\n",
      "137202/137202 [==============================] - 72s 528us/step - loss: 3.4881 - acc: 0.3494 - val_loss: 5.8000 - val_acc: 0.1792\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.67287\n",
      "Epoch 24/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4894 - acc: 0.3504 - val_loss: 5.8001 - val_acc: 0.1791\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5.67287\n",
      "Epoch 25/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4894 - acc: 0.3496 - val_loss: 5.8001 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 5.67287\n",
      "Epoch 26/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4893 - acc: 0.3500 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5.67287\n",
      "Epoch 27/50\n",
      "137202/137202 [==============================] - 72s 528us/step - loss: 3.4888 - acc: 0.3495 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 5.67287\n",
      "Epoch 28/50\n",
      "137202/137202 [==============================] - 72s 528us/step - loss: 3.4881 - acc: 0.3502 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5.67287\n",
      "Epoch 29/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4868 - acc: 0.3505 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5.67287\n",
      "Epoch 30/50\n",
      "137202/137202 [==============================] - 72s 528us/step - loss: 3.4891 - acc: 0.3507 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 5.67287\n",
      "Epoch 31/50\n",
      "137202/137202 [==============================] - 73s 531us/step - loss: 3.4864 - acc: 0.3501 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 5.67287\n",
      "Epoch 32/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4890 - acc: 0.3508 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.67287\n",
      "Epoch 33/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4882 - acc: 0.3492 - val_loss: 5.8002 - val_acc: 0.1793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss did not improve from 5.67287\n",
      "Epoch 34/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4886 - acc: 0.3500 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 5.67287\n",
      "Epoch 35/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4885 - acc: 0.3501 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5.67287\n",
      "Epoch 36/50\n",
      "137202/137202 [==============================] - 72s 527us/step - loss: 3.4898 - acc: 0.3496 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5.67287\n",
      "Epoch 37/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4887 - acc: 0.3504 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5.67287\n",
      "Epoch 38/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4880 - acc: 0.3505 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5.67287\n",
      "Epoch 39/50\n",
      "137202/137202 [==============================] - 72s 525us/step - loss: 3.4867 - acc: 0.3498 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.67287\n",
      "Epoch 40/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4883 - acc: 0.3495 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 5.67287\n",
      "Epoch 41/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4888 - acc: 0.3501 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 5.67287\n",
      "Epoch 42/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4883 - acc: 0.3498 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 5.67287\n",
      "Epoch 43/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4880 - acc: 0.3501 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 5.67287\n",
      "Epoch 44/50\n",
      "137202/137202 [==============================] - 73s 529us/step - loss: 3.4896 - acc: 0.3493 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 5.67287\n",
      "Epoch 45/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4864 - acc: 0.3503 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 5.67287\n",
      "Epoch 46/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4884 - acc: 0.3497 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 5.67287\n",
      "Epoch 47/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4880 - acc: 0.3505 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 5.67287\n",
      "Epoch 48/50\n",
      "137202/137202 [==============================] - 72s 525us/step - loss: 3.4883 - acc: 0.3499 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 5.67287\n",
      "Epoch 49/50\n",
      "137202/137202 [==============================] - 72s 526us/step - loss: 3.4888 - acc: 0.3494 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 5.67287\n",
      "Epoch 50/50\n",
      "137202/137202 [==============================] - 72s 527us/step - loss: 3.4889 - acc: 0.3497 - val_loss: 5.8002 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 5.67287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 50\n",
    "SEQ_LENGTH = 5\n",
    "EMBEDDING_DIM = 169\n",
    "\n",
    "X_train, X_val, y_train, y_val = generateTrainData(cut_word_list, word_to_index, SEQ_LENGTH)\n",
    "\n",
    "Hidden_size_1 = 512\n",
    "Hidden_size_2 = 512\n",
    "Hidden_size_3 = 256\n",
    "\n",
    "print('\\nSEQ_LENGTH: ', SEQ_LENGTH, ', EMBEDDING_DIM: ', EMBEDDING_DIM, ', Hidden_size_1: ', Hidden_size_1, ', Hidden_size_2 ', Hidden_size_2, ', Hidden_size_3', Hidden_size_3)\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_to_index))\n",
    "input_shape = (SEQ_LENGTH,)\n",
    "x_train_in = Input(input_shape, dtype='int32', name=\"x_train\")\n",
    "\n",
    "# word_index存储的是所有vocabulary的映射关系\n",
    "embedding_layer = Embedding(nb_words, EMBEDDING_DIM, input_length=SEQ_LENGTH)(x_train_in)\n",
    "print(\"embedding layer is::\", embedding_layer)\n",
    "print(\"build model.....\")\n",
    "\n",
    "# return_sequences=True表示返回的是序列，否则下面的LSTM无法使用，但是如果下一层不是LSTM，则可以不写\n",
    "lstm_1 = Bidirectional(LSTM(Hidden_size_1, name=\"LSTM_1\", return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(embedding_layer)\n",
    "#drop_1=Dropout(0.2)(lstm_1)\n",
    "lstm_2 = Bidirectional(LSTM(Hidden_size_2, name=\"LSTM_2\", return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(lstm_1)#(drop_1)\n",
    "#drop_2=Dropout(0.2)(lstm_2)\n",
    "lstm_3 = Bidirectional(LSTM(Hidden_size_3, name=\"LSTM_3\", dropout=0.2, recurrent_dropout=0.2))(lstm_2)#(drop_2)\n",
    "#drop_3=Dropout(0.2)(lstm_3)\n",
    "dense = Dense(nb_words, activation=\"softmax\", name=\"Dense_1\")(lstm_3)#(drop_3)\n",
    "\n",
    "model = Model(inputs=x_train_in, outputs=dense)\n",
    "print(model.summary())\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "print(\"Train....\")\n",
    "\n",
    "# save tensorboard info\n",
    "tensorboard = TensorBoard(log_dir='./tensorboard_log/')\n",
    "# save best model.\n",
    "checkpoint = ModelCheckpoint(filepath='./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5',\n",
    "                             monitor='val_loss', mode='min', save_best_only=True, save_weights_only=False, period=1, verbose=1)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "callback_list = [tensorboard, checkpoint, reduce]\n",
    "\n",
    "history_record = model.fit(X_train, y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callback_list\n",
    "                         )\n",
    "model.save('./model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5')\n",
    "\n",
    "del X_train, X_val, y_train, y_val\n",
    "gc.collect()\n",
    "del x_train_in, embedding_layer, lstm_1, lstm_2, lstm_3, dense, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 5\n",
    "model_file = './model_epoch50_2lstm_1dense_seq50_phrase_based_best.h5'\n",
    "word2index_file = './word_to_index_word.txt'\n",
    "index2word_file = './index_to_word_word.txt'\n",
    "model, word2index, index2word = loadParam(model_file, word2index_file, index2word_file)\n",
    "generate_maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "边塞前花染红尘。帝澜我我梦里。藏我纵然年华。或当老酒自我。烬窗下。满琴意。任罪为行。用明月极胸丘。人人绘骨过往。最低心。像天灵兰唱。烈与墨怀覆。为君共赏眷轻怨念。心年谁敌解。乐绎与你长何。年少转途娥。斜阳寒寒。结紫罗缠绵重规连。像一端十尘。弦风急。可有平生不曾负得。桃花坞。结归去。如得当日孤行中。此后。童法枯藤。抚剑阁卷。埋葬了谁的称慕。衷的心酒寻画。等松风泣夜。说人抚琴枯凉。痛伴透过数泊的儿望。\n"
     ]
    }
   ],
   "source": [
    "start = \"边塞\"\n",
    "print(lyrics_generate(start, model, word2index, index2word, SEQ_LENGTH, generate_maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAccuray(history_record):\n",
    "    \"\"\"\n",
    "    plot the accuracy and loss line. \n",
    "    :param history_record:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    accuracy_train = history_record.history[\"acc\"]\n",
    "    accuracy_val= history_record.history[\"val_acc\"]\n",
    "    loss_train = history_record.history[\"loss\"]\n",
    "    loss_val = history_record.history[\"val_loss\"]\n",
    "    epochs = range(len(accuracy_train))\n",
    "    plt.plot(epochs, accuracy_train, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, accuracy_val, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss_train, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"./train_data/all_5.txt\"\n",
    "# cut_word_list = cutWords(file_name)\n",
    "# word_to_index, index_to_word = mapWords(cut_word_list)\n",
    "# X_train, X_val, y_train, y_val = generateTrainData(cut_word_list, word_to_index)\n",
    "# history_record = model_lstm(X_train, X_val, y_train, y_val, word_to_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
